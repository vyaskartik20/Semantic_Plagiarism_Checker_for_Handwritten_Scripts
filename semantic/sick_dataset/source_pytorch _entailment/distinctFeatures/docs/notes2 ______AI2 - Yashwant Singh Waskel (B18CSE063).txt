# Tree Search: Extra work!
-> If the algorithm we are using failed to detect the repeated states or nodes then the search tree will end up performing steps no longer needed.
   For example, consider a graph of 4 states, from each state there are two edges directly connected to second state, from second two edges to forth state and so on.
   If we construct tree for this graph then each node will have two same child and so on. So agent will end up exploring same node more than once. So we should keep track of expanded 
   nodes.

# Graph search
-> 1) We should never expand a state or node twice. For that keep track of visited nodes.
   2) Implementation :-
      2.1) With tree search also create a set of expanded states("closed set") and update it after each expansion of states.
      2.2) After taking out a node from the fringe, expand this node if it has not expanded before or this state is not in the set.
      2.3) If node is in set, skip it, else expand it.
   3) Store the closed set as a 'set' and not a 'list' because search time of set is less than that of a list.  
   4) Optimality :- We may not get the optimal solution but we will get a sub-optimal solution because of above constraints.
                    For example, lets perform A* graph search on given state space graph,
           
                            h=4     
                   --1----->(A)---1-------                                              S(0+2)
                  |                      |                                             /      \
                  |                      v                                            /        \
              h=2(S)                 h=1(C)----3---->(G)h=0                       A(1+4)       B(1+1)                
                  |                      ^                                          |            |
                  |                      |                                          |            |
                   ---1---->(B)---1-------                                        C(2+1)       C(3+1)
                            h=1                                                     |            |
                                                                                    |            |
                     Fig. State space graph                                       G(5+0)       G(6+0)
                  
                                                                                     Fig. Search tree {node(g(n)+h(n))}
           
                If we look at the search tree for above state space graph and if we search the tree with closed set, then start from S, least f(n) value is of B so expand B, then expand 
                C and then we will reach to Goal state(G).
                But this is a sub-optimal solution whereas optimal solution is when we expand S, then A, then C, and reached to G.

# Consistency of Heuristics
-> 1) Estimated heuristic costs <= actual costs
      1.1) In  case of admissibility:-
                Heuristic cost  <= actual cost to goal
                For example, consider 3 nodes, 
                                             A---1----> C ---3---->G
                                         the heuristic value of A is equal to 4.
                                     =>  h(A) <= actual cost from A to G

      1.2) In case of consistency :-
                Here, we consider heuristic arc cost and actual cost for each arc, consider arc between the path from source to goal node.
               
                             Heuristic arc cost <= actual cost for each arc
                
              Difference between heuristics of two states in the path <= cost of arcs between that two states
              For example, A------> C -------> G

                      h(A) - h(C) <= cost(A to C)
  
      1.3) Consequences of consistency:-
             The f value (f(n) = g(n) + h(n)) along a path never decreases when we move towards the goal,
                       h(A) <= cost(A to C) + h(C) 

             With consistent heuristic A* graph search is optimal.

# Optimality of A* graph search
-> 1) In tree search, A* graph search algorithm expands nodes which are in increasing f value.
   2) For any state, lets say state s, the nodes that reach s optimally are given more priority and expanded before nodes that reach s suboptimally.
   3) Because of above two statements, we can say that A* search is optimal.

# Summary of Optimality
-> In case of tree search:
                          - A* search is optimal when heuristic is admissible i.e., heuristic cost <= actual cost
                          - When heuristic value is equal to zero, UCS becomes a special case.

   In case of graph search:
                           - A* search is optimal when heuristic is consistent i.e., h(A) - h(C) <= cost(A to C) 
                           - As h=0 is always consistent therefore, UCS is optimal.

   If heuristic is consistent it also implies that it is admissibile.
   
# Planning: It is sequences of actions
           - In this, the path to the goal matters and different paths have various cost and depths
           - With the help of heuristic we can get problem specific guidance

  Identification: It is assignments to variables
           - In this the priority is the goal state and not path.
           - For some formulations all paths are at the same depth
           - Problem which are specialized for identification problems are CSPs(Constraint Satisfaction Problems)

# Standard Search Problems
-> - In past search problems learned, these problems can be solved by searching in a space of states.
   - In these, each state is like a black box(arbitrary data structure) with no internal strtucture.
   - In these, the goal test can be any function over states, agent use this function to reach to goal state. 
   - Successor function depends on the algorithm we use.

# Constraint Satisfaction Problems(CSPs)
-> - It is a special subset of search problems.
   - CSP consists of three components
      - Xi is a set of variables
      - D is a set of domains consist of allowable values, one for each variable. State is defined by Xi and D.
      - Goal test is a set of constraints which specify allowable combinations of values for subsets of variables.

   - Solving CSP:
                 - Define a state space and notion of a solution. Each state in CSP is defined by an assignment of values to some or possibly all variables.
                 - Consistent assignment is one that does not voilate any constraint.
                 - If every variable is assigned it is called complete assignment.
                 - Partial assignment assigns values to only some of the variables.
   
   - Example in which CSP is used is map coloring problem, N-Queens problem. 

# Map Coloring Problem
-> Given a map with different blocks for each area. Our task is to color the map in such a way that no two adjacent block have same color(Adjacent block means blocks sharing same boundary),
   this is also the constraint to this problem.

   Consider the map with 6 blocks or areas,
                     ___________________________
                    /      |  NT  |            /
                    |      |______|     Q     |
                    |      |      |___________/
                    |  WA  |      |   NSW    |
                    |      |  SA  |__________/    _____
                    |      |      |    V     |   |  T  |
                    |______|______/__________|   |_____|

   - Variables: WA, NT, Q, NSW, V, SA, T (Here, variables are different blocks which we need to color, T is an independent block)
   - Domains: D = {red, green, blue} (Domain is the set of colors which we can give to blocks)
   - Constraints: Constraint is that the adjacent blocks should not have same color.
                  Consider adjacent blocks WA and NT,
                  Implicit WA cannot be equal to NT.
                  Explicit is that (WA, NT) can be assigned {(red, green), (red, blue), (blue,green),.........}
   - Solutions are the assignments which satisfy all constraints.
     For example, {WA = red, NT = green, SA = blue, Q = red, NSW = green, V = red, T = any color}

# N-Queens Problem
-> Given a N x N chess board, place N queens in such a way that no two queens can attack each other(Queen can move forward, backward, up, down and diagonally).
   
   Formulation 1:-

   Variables: X(i,j), X is the position on the chess board, 1 <= i,j <= N
   Domains: {0,1} which represent value of variable X, if X(i,j)=1 there is a queen on this position and if X=0 then no queen at X(i,j).
   Constraints: 
               For all i,j,k, such that coordinate (a,b) should be (1,1) <=(a,b) <= (N,N). 
               1) (X(i,j), X(i,k)) belongs to {(0,0), (0,1), (1,0)}, in a row there cannot be more than one queen.
               2) (X(i,j), X(k,j)) belongs to {(0,0), (0,1), (1,0)}, in a column there cannot be more than one queen.
               3) (X(i,j), X(i+k, j+k)) belongs to {(0,0), (0,1), (1,0)}, in a diagonal(/) there cannot be more than one queen.
               4) X(i,j), X(i+k, j-k)) belongs to {(0,0), (0,1), (1,0)}, in a diagonal(\) there cannot be more than one queen.
               5) Summation of all X(i,j) = N, which means that total N queens have been placed at its respective position.

   Formulation 2:-

   Variables: Qk, represent N variables one for each queen of a row, 1 <= k <= N
   Domains: {1, 2, 3,...., N}, it represent column in which queen can be placed
   Constraints: 
               Implicit: No queens should be in attacking position to another
                         For all i,j, non-threatning(Qi, Qj)
               Explicit: For all (Q1,Q2) possible positions can be {(1,3), (1,4),...}
                         (1,3) means Q1 queen of first row is at column 1 and Q2 queen of second row is at column 3.

# Constraint Graphs
-> Consider the map coloring problem discussed above,
   We can make graph for this map with different blocks as vertex(node) and the common boundaries as edges connecting two blocks.
   - In this graph the constraint is between pairs of nodes can be called binary constraint graph and the corresponding problem is binary CSP(every constraint has two variables). Binary 
     constraint relates two variables e.g., SA not equal to NSW.
   - In binary constraint graph, nodes represent variables and arcs represent contraints.
   - With the help of graph structure,many general-purpose CSP algorithms use it to speed up the search. For example, in map coloring, block T is an independent sub-problem.

# Cryptarithmetic
-> It is a CSP, where each letter stands for a distinct digit and the aim is to substitute each digit with a letter such that the result is arithmetically correct.
   For example, consider a cryptatihmetic problem
 
                 T  W  O 
              +  T  W  O
	      ___________
              F  O  U  R   

   '+' denotes standard addition symbol 

   Variables: letters used {F, T, W, O, U, R} and the carry for each place {X1, X2, X3}
              Therefore, variables are  F, T, W, O, U, R, X1, X2, X3
   Domains: Considering it as base ten summation, domain is {0,1,2,3,4,5,6,7,8,9}
   Constraints: 
               alldiff(F, T, U, R, W, O) i.e., different variables stands for different digits.
                
               O + O = R + 10.X1,  adding ones places and getting carry as X1
               X1 + W + W = U + 10.X2,  adding carry X1 and tens places and getting carry X2
               X2 + T + T = O + 10.X3,  adding carry X2 and hundreds places and getting carry X3
               10.X3 = F,

   Constraint graph for cryptarithmetic-
                                        Edges denotes variables connected.
                                             __
                                            |__|--------------------->alldiff (all different constraint)
                                       /  / /  \  \  \
                                      /  / /    \  \  \
                                     F  T  U     W  R  O---------
                                     |  |   \__  |   \  |       |
                                    _|_  \___  \_|_   \_|_      |
                                   |___| |___|  |__|  |___|     |   This four boxes denotes column addition constraints
                                      \  / | \  /   \   /       |
                                       \/  |  \/     \ /        |
                                       X1  |  X2      X3        |    X1, X2, X3 represent the carry digits for three columns
                                           |____________________|

              This is not a binary constraint graph.

# Suduko
-> Another example of CSP, consider a 9 x 9 suduko involving a grid of 81 squares. The grid is divided into nine blocks each containing nine squares. Some entries filled among 81 squares.
   
   Variables: variables are each empty square
   Domains: {1,2,3,4,5,6,7,8,9} for a 9 x 9 suduko
   Constraints:
               - 9-way alldiff for each column (Each column should have all different digits from 1 to 9)
               - 9-way alldiff for each row (Each row should have all different digits from 1 to 9)
               - 9-way alldiff for 9 blocks of 9 squares (Each block should have all different digits from 1 to 9)

# The Waltz algorithm
-> The waltz algorithm is used for interpreting line drawings of solid polyhedra as 3D.
   It is a kind of CSP for AI computation.
   Variables:- Intersections in the drawing
   Domains:- Consider a cube with one small cube cutted out from one of its vertex. Now we can say that, domains are inward intersection(it is of part cutted out) and outward intersection.
   Constraints:- The adjacent intersections are constraints to each other.
   In this, solutions are physically realizable 3D interpretations.

# Varieties of CSPs
-> There are two types of CSPs in terms of variables:-
   1) Discrete variables
    - It consists of both finite and infinite domains.
    - In finite domain, suppose there are n values then domain size d implies O(d^n) complete assignments(i.e., every variable is assigned).
    - Infinite domains consists of integers, strings, etc. Linear constraints are solvable and non-linear constraints are uindecidable.
    - Boolean CSPs, include boolean satisfiability(NP-complete) are examples of CSPs with finite domain.
    - Job scheduling problem is an infinite domains discrete variable CSP. In this variables are start or end time for each job.

   2) Continuous variables
    - It is a kind of time stamp(time of occurrence of a particular event). 
    - Example is start/end times for Hubble Telescope observations.
    - Linear constraints(eg. aX + bY + c) are solvable in polynomial time by LP(Linear Programming) methods. LP methods are used to get best outcome in a mathematical model when there are 
      linear relationships.

# Varieties of Constraints
-> Unary Constraint:
                    It is a constraint including single variable. It is equivalent to reducing domains.
                    For example, consider map problem, area SA not equal to green. 
               
   Binary Constraint:
                    It is a constraint including pairs of variables.
                    For example, in map problem SA not equal to WA.

   Higher-order constraints:
                            This constraints involve 3 or more than three variables.
                            Cryptarithmetic column constraints is an example of higher-order constraint. 

# Real-World examples of CSPs
-> 1) Assignments problems: e.g., who will teach which class?
   2) Timetabling problems: there are some courses and batches, schedule the courses so that students selected courses time do not overlap.
   3) Hardware configuration: Consider the hardware board, place the transistors, capacitors, etc. in such a way that maximum of them can be placed on hardware to maximize hardware's 
      utility.
   4) Transportation scheduling: Scheduling of trains, flights, buses and many other vehicles. This problem consists of variables, domains and constraints.
   5) Factory scheduling: Managing raw materials, intermediates and production capacity are allocated to meet demand. This is also a kind of CSP.
   6) Circuit layout
   7) Fault diagnosis

# Standard Search Formulation
-> States defined by the values:
   - Initial state: Initial state is empty assignments i.e., none of the variables have assigned the value from domain.
   - Successor function: As moving ahead in search space, start assigning value to an unassigned variable.
   - Goal test: The current assignment have satisfied all the constraints and are complete is our solution. Here also, the solution is the goal and not the path.

# Search Methods
-> Consider the map coloring problem graph with edges as sharing boundary between two regions.
   
   Through BFS:-
   Start state: State which have all variables and none of them is assigned. In this map, there will be 7 variables. Therefore, at each keep track of each variables and color assigned 
   to it or variables unassigned. 
   At start state, all the variables are unassigned. At next level all 7 variables were assigned and there will be multiple assignments also. As here are three values so for start state
   we have 21 children. Picking any node and assigning one of the three values.
   In BFS, we perform one assignment at each level and move to another level. Beacause of branching factor tree will be huge. Our goal is at the end.
   Depth of the search tree is number of variables.
   Disadvantage of BFS is that we have to traverse the whole tree.

   Through DFS:
   At start state no variables are assigned any value. At next level assign a color to an unassigned variable. Now move to next level rather than moving to the same level of the node and 
   assign value to an unassigned variable.
   There are chances of getting a solution in 7 steps in case of the above map coloring graph. Thus there are advantages through DFS than that of BFS in case of CSPs.

   Problems with naive search:-
   We have to perform to go through lot of search in the tree.

# Backtracking Search
-> In DFS we continue with non-satisfying assignments and backtrack when achieved complete assignment. We can imporve it by backtracking whenever dfs chooses values for one variable at a 
   time and backtracks when a variable has no satisfying value to assign.
   Backtracking search is the basic uninformed algorithm for solving CSPs because we do not have information other than constraints for goal.
   Process to achieve the target:-
   - Assigning order to the variables. Choosing next unassigned variable in an order. 
     For example, consider the above map coloring problem, after assigning WA value equal to red and green to NT, now we should go for SA for which only one value possible which is blue 
     rather than assigning Q.
     i.e., we only need to consider assignments to a single variable at each step.

   - After assigning a value to a variable check that it is not voilating constraints with other assignments. If that happens then backtrack and go for other possiblities.
     For these there might be some more computation to check the constraint.

   By improving above two methods in DFS, it will be the backtracking search problem.

   Pseudo-code for backtracking search:- 

                |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
                ||                                                                                 ||
                ||         function BACKTRACKING-SEARCH(csp) returns a solution, or failure        ||
                ||            return BACKTRACK({ }, csp)                                           ||
                ||                                                                                 ||
                ||         function BACKTRACK(assignment, csp) returns a solution, or failure      ||
                ||            if assignment is complete then return assignment                     ||
                ||            var ← SELECT-UNASSIGNED-VARIABLE(csp)            <-------------------------------- Choosing next unassigned variable
                ||            for each value in ORDER-DOMAIN-VALUES(var , assignment, csp) do      ||
                ||                if value is consistent with assignment then                      ||
                ||                    add {var = value} to assignment                              ||
                ||                    inferences ← INFERENCE(csp, var , value)                     ||
                ||                    if inferences (not equal to) failure then                    ||
                ||                       add inferences to assignment                              ||
                ||                       result ← BACKTRACK(assignment, csp)                       ||
                ||                       if result (not equal to) failure then                     ||
                ||                          return result                                          ||
                ||                remove {var = value} and inferences from assignment              ||
                ||            return failure                                                       ||
                ||                                                                                 ||       
                |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||

                Backtracking = DFS + variable-ordering + fail-no-violation

# Improving backtracking
-> Methods to improve backtracking:-
   1) Filtering:- 
                 Keep track of variables which are unassigned and remove the values from domain for this variable with which constraints are definitely not satisfied.
                 Forward checking:- It is a kind of filtering in which we shrink the domain of variables by removing values which do not satisfy constraints.
                                    For example, consider map of above map coloring problem with its domain.
                                    
                                    Variable           Domain              Value assigned
                                      WA          {red, green, blue}           NIL
                                      NT          {red, green, blue}           NIL
               (i)                    Q           {red, green, blue}           NIL
                                      NSW         {red, green, blue}           NIL
                                      V           {red, green, blue}           NIL
                                      SA          {red, green, blue}           NIL

                                   Lets assign WA = red, now shrinking domain of other variables that do not satisfy constraint.
                                     
                                    Variable           Domain              Value assigned
                                      WA          {red, green, blue}           Red
                                      NT          {green, blue}                NIL        <-------------- WA and NT are neighbous therefore red is removed form domain of NT
               (ii)                   Q           {red, green, blue}           NIL
                                      NSW         {red, green, blue}           NIL
                                      V           {red, green, blue}           NIL
                                      SA          {green, blue}                NIL        <-------------- WA and SA are neighbous therefore red is removed form domain of SA

                                   Lets assign Q = green, new domains are
      
                                    Variable           Domain              Value assigned
                                      WA          {red, green, blue}           Red
                                      NT          {blue}                       NIL        <-------------- Q and NT are neighbous therefore green is removed form domain of NT
               (iii)                  Q           {red, green, blue}           Green
                                      NSW         {red, blue}                  NIL        <-------------- WA and NT are neighbous therefore green is removed form domain of NSW
                                      V           {red, green, blue}           NIL
                                      SA          {blue}                       NIL        <-------------- WA and NT are neighbous therefore green is removed form domain of SA

                                   Lets assign V = blue, new domains are
 
                                    Variable           Domain              Value assigned
                                      WA          {red, green, blue}           Red
                                      NT          {blue}                       NIL       
               (iv)                   Q           {red, green, blue}           Green
                                      NSW         {red}                        NIL        <-------------- WA and NT are neighbous therefore blue is removed form domain of NSW
                                      V           {red, green, blue}           Blue
                                      SA          {}                           NIL        <-------------- WA and NT are neighbous therefore blueis removed form domain of SA

                                   As domain of SA becomes empty we will backtrack form here and try new possiblilties.
                                   With forward checking we can not predict future constraint which will be violated.
            
                    Constraint Propagation:-
                                    Through constraint propagation we will detect failure before assigning value to any assignment.
                                    For example, consider the (iii) table above, as domain of NT and SA are {blue} but as they are neighbours so we cannot assign same value to them. So 
                                    here we detect the failure and we backtrack from here instead of assigning Q any value.

# Consistency of a Single arc
-> An arc X -> Y is consistent if and only if for every x in the tail there is some y in the head which could be assigned a value without violating a constriant.
   Consider the above map's constraint graph with directed arcs, lets check its consistency,
   WA -> NT, WA is head and NT is tail. Domain of NT is {red, blue, green}.
   Assigning WA = red. Assigning blue or green to NT does not violate any constraint. If we assign red to NT constraints are violated. So to make it consistent remove red value from domain
   of tail node i.e., NT.
   Always remove values from domain of tail node only.
   Consider WA -> Q, we can assign any value to Q as they are not neighbours and we do not violate any constraint. So constraints are satisfied with any value.
   Every time shrinking domain of any tail node also check for other arcs also. In this map, there are 36 arcs.

# Arc Consistency of an Entire CSP
-> Through simple propagation we can make all arcs consistent.

   Consider the example of filtering forward checking part (iii).
   
                                      Variable           Domain              Value assigned
                                      WA          {red, green, blue}           Red
                                      NT          {blue}                       NIL        
                                      Q           {red, green, blue}           Green
                                      NSW         {red, blue}                  NIL         
                                      V           {red, green, blue}           NIL
                                      SA          {blue}                       NIL        

          Consider arcs,
                       WA  -> NT   consistent
                       NT  -> WA   consistent
                       Q   -> WA   consistent
                       SA  -> NT   inconsistent (We can only assign blue to SA and domain of NT does not have value other than blue. So it is violating constraints and therefore 
                                                 inconsistent. So we backtrack from here.)
                       V   -> NSW  consistent (For any value we assign to V there are other values for NSW so that constraints are not violated.)
                       SA  -> NSW  consistent (Assigning blue to SA we can assign red to NSW)
                       NSW -> SA   inconsistent (Assigning blue to NSW, we cannot assign any other value to SA. To make it consistent remove blue from domain of NSW and check for other
                                                 arcs also)
           
          Important is to check for neighbours of X whenever removing value from tail.
          Arc consistency helps in detecting early failures.
          
    Pseudo code for above is 

           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
           ||                                                                                                      ||
           ||      function AC-3(csp) return the CSP, possibly with reduced domains                                ||
           ||         inputs: csp, a binary CSP with variables {X1, X2, X3, ....Xn}                                ||
           ||         local variables: queue, a queue of arcs, initially all the arcs in csp                       ||
           ||                                                                                                      ||
           ||         while queue is not empty do                                                                  ||
           ||            (X1, X2) <-- REMOVE-FIRST(queue)                                                          ||
           ||            if REMOVE-INCONSISTENT-VALUES(Xi, Xj) then                                                ||
           ||               for each Xi in NEIGHBOURS[Xi] do                                                       ||
           ||                  add (Xk, Xi) to queue                                                               ||
           || _____________________________________________________________________________________________________||
           ||                                                                                                      ||
           ||      function REMOVE-INCONSISTENT-VALUES(Xi, Xj) returns true iff succeds                            ||
           ||         remove <-- false                                                                             ||
           ||         for each x in DOMAIN[Xi] do                                                                  ||
           ||            if no value y in DOMAIN[Xj] allows (x, y) to satisfy the constriant Xi <--> Xj	           ||
           ||               then delete x from DOMAIN[Xi];  removed <-- true                                       ||
           ||         return removed                                                                               ||
           ||                                                                                                      ||
           ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
  
           Runtime: O((n^2).(d^3)), can be reduced to O((n^2).(d^2)), where n is number of variables and d is size of domain.
                    We are checking for n x n arcs, comparing each value from domain of tail node with other nodes which gives d x d, whenever we remove any value again run the same process
                    which gives d x d x d.

# Limitations of Arc Consistency
-> After enforcing arc consistency we can have three possiblities:
   1) We have one solution left.(In table (iii), NSW -> NT)
   2) We can have multiple solutions left.(In table (iii), WA -> Q)
   3) We can have no solutions left.(In table (iii), SA -> NT) 

   Arc conistency runs inside backtracking search.

# Ordering: Minimum remaining values
-> Choose the variable with least domain size after first assignment.
   In above map, after assigning red to WA least domain size will be of NT and SA.
                 Choose NT and assign green to it.
                 Choose SA and assign blue to it. After that least domain size will be of Q which is one.
                 Assign red to Q.

   Always choosing minimum domain rather than maximum size domain so not to violate constraints.
   It is also called "most constrained variable"

# Ordering: Least Constrianing value
-> Choose the variable such that the domain of its neighbours shrink by minimum amount.
   We may perform more computation then in filtering.
   This makes feasible even 1000 queens problem.

## LOCAL SEARCH AND OPTIMIZATION

# Local search
-> In local search, the agent just keep track of the current state(rather than multiple paths) in which a little memory is used and can only move to the neighbouring states. In local 
   search, we does not care about path taken.
   There are many chances in which we can get reasonable solutions in large state spaces for which systematic algorithms are unsuitable.

# Pure Optimization problems
-> Local search algorithms are useful in solving pure optimization problems in which the aim is to find the best solution according to an objective function(Like heuristic function, 
   objective function is a function which gives the maximum or minimum value as per the problem for each state).
   The goal is to find the state in which value of objective function is maximum or minimum depending on problem.
  
# Trivial Algorithms
-> In local search, when we generate states randomly it is called random sampling.
   When we randomly pick a neighbour of the current state it is random walk.
   
# Hill-climbing
-> It is a kind of greed local search because it selects best neighbour irresponsible about where to go next.
   
   Consider below the pseudo code for hill climbing problem:-

              function HILL-CLIMBING(problem) returns a state that is a local maximum       (Local maximum is a peak that is higher than each of its neighboring states but lower than global
                                                                                             the global maximum)
                 input: problem, a problem                 
                 local variables: current, a node.
                                  neighbour, a node.

                 current <-- MAKE-NODE(INITIAL-STATE[PROBLEM])
                 loop do
                      neighbor <-- a highest-valued successor of current
                      if VALUE[neighbor] <= VALUE[current] then return STATE[current]
                      current <-- neighbour

   Given a problem and variables or states.
   Start with any state, from current state look for neighbours and move to the neighbour with higher value than current state otherwise current state is best in locally(among neighbouring states).
   Above pseudo code is for maximum inequality.

   - there is a loop that continously moves in direction of increasing value and terminates when reaches a peak i.e., where no neighbour has greater value.
   - In this, value can be either objective function or heuristic function.
   - As it is local search we do not look ahead of the immediate neighbours.
   - If there are more than one neighbours with equal objective value we can choose randomly.

# N-Queens problem
-> Place N queens on a N x N chessboard such that no one attacks others.
   Converting it into an optimization problem.
   Objective function will be the number of pairs of queens attacking each other.
   Aim is to minimize the objective function to zero.

   State space - configurations of all N queens on the board.
   Successor function - Can only move each queen to another square in the same column.
   Heuristic function - number of pairs of queens attacking each other. We have to minimize heuristic function.

#  Hill climbing on 8-queens
-> Consider a random start states of 8-queens, around 14% of the time we come up with the solution and 86% of the time we get stuck at local minimum. 
   Whenever it come up with the solution only 4 steps on average are required.
   When it stuck 3 steps on average.

# Drawbacks of Hill Climbing
-> 1) Local maxima :- Through hill climbing algorithm it reaches around local maxima then drawn upward towards the peak and got stuck with no where else to go.
   2) Plateaus :- Plateau is a region of flat area of state space landscape. It is flat local maxima from where no greater peak exist. We stop at flat area.
   3) Diagonal ridges :- It is the sequence of local maxima that is very difficult for algorithm to find.

# Escaping Shoulders: Sideways move
-> Sideways movement helps in escaping the plateau. If there are no downhill or uphill moves possible, it allows sideways moves so that algorithm can escape. To avoid infinite loops we need to put a 
   limit on the possible number of sideways moves.

   For 8-Queens:-
                 Allowing sideways moves and keeping its limit of 100. There is percentage raise in solving problem instances from 14 to 94%.
                 Drawback is that number of steps have increased. 

# Tabu search
-> - Tabu search prevent from returning quickly to same state. Create a queue of fixed length and add most recent state visited to queue and pop out old states.
   - As the size of tabu list increases, hill-climbing asymptotically become non-redundant i.e., never visit same state twice.
   - A reasonable sized tabu list improves performance of hill climbing.

# Hill climbing: stochastic variations
-> In standard hill climbing, we got stuck in local minima. So to avoid that we insert some random walk and random restart in hill climbing.
   - Random walk implies that with some probability p we move to best neighbouring state and with probability (1-p) choose neighbouring state randomly. It will take us out of local minima.
   - In random restart, we start from different states in many iterations and move to best neighbouring state. So there are chances that starting at some iterations we can reach to global maximum 
     state. It ensures complete solution if performed many iterations.
   - Different variations in random restart:
     - For each restart we can terminate it on getting solution or run it for a fixed time.
     - Run a fixed number restarts or run indefinitely.
   - Applying hill climbing approach without sideways moves on 8-queens problem, 14% of the time we get the solution and 86% of the time we get stuck.
     Applyling hill climbing with random restart on 8-queens get us the solution. Approximately 7 restarts are required for getting a complete solution.
   Standard hill climbing is not complete as it stucks in local minima but with random walk it ensures asymptotically complete solution.

   - Combining random walk and random restart:
     Start from any state, choose best neighbour state then choose that neighbour with probabiliy p or choose other random neighbouring state with probability 1-p. Terminate at some point or restart 
     and start from any other state.

# Simulated Annealing
-> It is also one of local search approach.
   - Suppose we have to get to the global minimum.
   - If we just roll the ball from any uphill it definitely get stuck in some local minima.
   - If we can provide some kind of disturbance or shake it such that it can get out from local minima.
   - The intensity of shake should not be greater such that it goes away from global minimum. 
   - It picks the random move instead of best move.
   - Let the change in objective function is $, if $ is better than previous value, move to that state otherwise move to this state with probability propotional to $.
   - Through simulated annealing, there is always a chance of escaping from local minima(in case of minimization).

   Pseudo code of the algorithm:
   
              function SIMULATED-ANNEALING(problem, schedule) returns a solution state
                 inputs: problem, a problem
                         schedule, a mapping from time to "temperature"
                 local variables: current, a node
                                  next, a node
                                  T, a "temperature" controlling the probability of downward steps

                 current <-- MAKE-NODE(INITIAL-STATE[problem])
                 for t = 1 to infinity do
                      T <-- schedule[t]
                      if T = 0 then return current
                      next <-- a randomly selected successor of current
                      $E <-- VALUE[next] – VALUE[current]
                      if $E > 0 then current <-- next
                      else current <-- next only with probability e^($E/T)


     The inner loop is same as that of hill climbing with a bit difference that here instead of picking best move it picks a random move.
     If the move improves the situation it is accepted. Otherewise it accept with some probability. Probability decreases with a bad move i.e., evaluation get worst by amount $E.

     Some of the application in which simulated annealing is practiced:-
     - Solving VLSI layout problem, traveling salesman, graph partitioning, graph coloring, factory scheduling etc.

# Local beam search
-> It is another variant of hill climbing search.
   The idea here is to keep just one node in memory which seems to be an extreme reation to the memory problems.
   - Local beam search keeps track of k states, some randomly generated k states instead of only one state.
   - At each k states, generate successors of each states.
   - Among this successors of k states, there is a goal and the algorithm stops.
   - If there is no goal it selects k best successors among generated successors and again repeat the above three processes.

# Genetic algorithms
-> It is a varaint of stochastic beam search.
   Consider a pair of states or two parent states, now by cobmining these two parents successor states are generated rather than modifying a single state.
   This algorithm begins with a set of k randomly generated states and these set is called population.
   In this each state is represented as a string over a finite alphabet such as a string of 0's and 1's.
   With each state there is an objective function or a fitness function. A fitness function is a function which return higher values for better states.
   Consider the 8-queens problem, here state is the position of 8-queens each in a column. The fitness function will be the function which returns number of non-attacking pairs for queens.
   Some additional notions in genetic algorithm are:
   - Random selection: In a population of k states, the pairs are selected randomly based on there value of fitness. Then we take genetic of each organism from these pair and produce new successors.
   - Crossover: Two individuals are selected from random selection process and crossover sites are selected randomly. At these crossover sites genes are exchanged to form completely a new individual or say offspring.
   - Random mutation:  Randomly selected any point in any state after crossover and insert another genes in it.

   Consider a representation of 8-queens problem with each column has only one queen,

                              
                             8   0 0 0 0 0 0 1 0
                             7   0 0 0 0 1 0 0 0
                             6   0 1 0 0 0 0 0 0          String representation of this is
                             5   0 0 0 1 0 0 0 0                 16257483
                             4   0 0 0 0 0 1 0 0
                             3   0 0 0 0 0 0 0 1
                             2   0 0 1 0 0 0 0 0
                             1   1 0 0 0 0 0 0 0 


                  Illustration of genetic algorithm on 8-queens problem.


                                                           Crossover point/site                                              1 is mutated in place of 5    
                                                                     |                                                           |
                                                                     v                                                           v         
                       2 4 7 4 8 5 5 2 (24)(31%)___           __3 2 7|5 2 4 1 1___      ___3 2 7|4 8 5 5 2 ----------> 3 2 7 4 8 1 5 2
                                                   \_________/       |            \____/        |
                       3 2 7 5 2 4 1 1 (23)(29%)___/\___________2 4 7|4 8 5 5 2___/    \___2 4 7|5 2 4 1 1 ----------> 2 4 7 5 2 4 1 1   <-- No mutation
                                                   \                                                                       v------------------2 is mutated in place of 7
    It is not          2 4 4 1 5 1 2 4 (20)(26%)__  \___________3 2 7 5 2|4 1 1___      ___3 2 7 5 2|1 2 4 ----------> 3 2 2 5 2 1 2 4
   selected beacause                              \                      |        \____/            |
    of least    -----> 3 2 5 4 3 2 1 3 (11)(14%)   \____________2 4 4 1 5|1 2 4___/    \___2 4 4 1 5|4 1 1 ----------> 2 4 4 1 5 4 1 7
  fitness value                          ^                                                                                            ^--------- 7 is mutated at place of 1
                                         |                        Selection                  Crossover                   Mutation
                      4 random states    |                                                
                                       Fitness value                                        New states after
                                      (No. of nonattacking                                    crossover
                                        pairs)
                       More the fitness value more the chances of survival.
                       In selection process, two states are randomly selected based on fitness value. 

      
    Advantage of crossover is that it allows us to jump from one state to another state which cannot be possible even after applying some moves in the start state.

    Positive points of genetic algorithms:
    - Through random exploration it becomes possible to find solutions that are not possible through local search.

    Negative points:-
    - As we are selecting random states therefore there is lack of uncertainity. In selection process we select random states based on fitness value.

# Genetic algorithm for Travelling Salesman Problem
-> Given the set of cities and goal is to travel all the cities atmost once and return back to starting city in minimum cost.
   We will start with a representation of cities. For example consider there are 10 cities to visit, so its representation will be
                                                  [9 3 4 0 1 2 5 7 6 8]

   States are cities and fitness function will return the length of the path. So lesser the value more the chances of survival.
   Techniques for mutation:
   - Randomly choose any two cities and swap them only if swapping reduces path length or cost.
   - Another way is of considering all pairs and swapping the pair which reduces its cost.
   Method for crossover:-
   - Randomly select two parents.
   - Select first city from any one of the parent.
   - Compare the neighbouring cities paths in both parents and select the one with least fitness value.   
   - If a city in one parent is visited leave it and go for city of another parent. 
   - If cities in both parents are already appeared, randomly select another non-selected city and repeat the above process.                       

# Optimization of continuous functions
->  Hill climbing uses discretization as there are discrete states.
    Gradient space is same as hill climbing but it is in a continous space. For example, consider a 3-D space.

# Gradient Descent
-> Consider a continous function of n-variables: f(X1, X2, X3,......, Xn).
   - For computing the gradients, partial differentiation of the function with respect to each variable. This differentiation will provide us the direction of tangent which helps us for next move. In case of minimization, move in 
     downward direction of tangent.
   - In gradient direction take steps downhill depending on the value of lambda,
                    Xi <-- Xi - lamda*(gradients),
     If lambda is small, take small steps and if big take bigger steps.
     Choosing lambda:
                    Either start from small value and successively increase it until f increases or start from large values and successively decrease it.
   - Repeat the above steps.

     In case of downhill, we have to minimize the continuous variables.
 
     Another method is Newton-Raphson method applied to function minimization:
           In this to minimize the function f, we need roots of the equation f'(x)=0. Here we use single and double derivative of f.
                           x <-- x - f'(x)/f"(x)
           In case of x is a vector,
                          -x <-- x - f'(x)/f"(x)    
  
 
# References
-> 1) Slides
   2) Artificial intelligence A modern approach by Stuart Russell and Peter Norvig
   3) https://www.quora.com/What-is-the-different-between-discrete-variables-and-continuous-in-CSP-And-the-different-between-finite-and-infinite-domin-inside-discrete-variable
   4) https://www.planettogether.com/blog/what-is-factory-scheduling#:~:text=Factory%20Scheduling%20is%20the%20production,time%20communication%20of%20schedule%20changes.
   5) https://www.tutorialandexample.com/local-search-algorithms-and-optimization-problem/#:~:text=A%20pure%20optimization%20problem%20is,state%20from%20the%20current%20state.
   6) https://www.geeksforgeeks.org/genetic-algorithms/             