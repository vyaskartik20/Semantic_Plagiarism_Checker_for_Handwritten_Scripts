Once upon a time there was an old woman who loved baking gingerbread. She would bake gingerbread cookies, cakes, houses and gingerbread people, all decorated with chocolate and peppermint, caramel candies and colored frosting.

She lived with her husband on a farm at the edge of town. The sweet spicy smell of gingerbread brought children skipping and running to see what would be offered that day.

Unfortunately the children gobbled up the treats so fast that the old woman had a hard time keeping her supply of flour and spices to continue making the batches of gingerbread. Sometimes she suspected little hands of having reached through her kitchen window because gingerbread pieces and cookies would disappear. One time a whole gingerbread house vanished mysteriously. She told her husband, "Those naughty children are at it again. They don't understand all they have to do is knock on the door and I'll give them my gingerbread treats."
One day she made a special batch of gingerbread men because they were extra big. Unfortunately for the last gingerbread man she ran out of batter and he was half the size of the others.

She decorated the gingerbread men with care, each having socks, shirt and pants of different colors. When it came to the little gingerbread man she felt sorry for him and gave him more color than the others. "It doesn't matter he's small," she thought, "He'll still be tasty."
Once upon a time . . . as a merchant set off for market, he asked each of
his three daughters what she would like as a present on his return. The first
daughter wanted a brocade dress, the second a pearl necklace, but the third, 
whose name was Beauty, the youngest, prettiest and sweetest of them all, said
to her father:
   "All I'd like is a rose you've picked specially for me!"
   When the merchant had finished his business, he set off for home. However, 
a sudden storm blew up, and his horse could hardly make headway in the howling
gale. Cold and weary, the merchant had lost all hope of reaching an inn when
he suddenly noticed a bright light shining in the middle of a wood. As he drew
near, he saw that it was a castle, bathed in light.
   "I hope I'll find shelter there for the night," he said to himself. When he
reached the door, he saw it was open, but though he shouted, nobody came to
greet him. Plucking up courage, he went inside, still calling out to attract
attention. On a table in the main hall, a splendid dinner lay already served. 
The merchant lingered, still shouting for the owner of the castle. But no one 
came, and so the starving merchant sat down to a hearty meal.
   Overcome by curiosity, he ventured upstairs, where the corridor led into
magnificent rooms and halls. A fire crackled in the first room and a soft bed 
looked very inviting. It was now late, and the merchant could not resist. He 
lay down on the bed and fell fast asleep. When he woke next morning, an 
unknown hand had placed a mug of steaming coffee and some fruit by his
bedside.
   The merchant had breakfast and after tidying himself up, went downstairs to
thank his generous host. But, as on the evening before, there was nobody in 
sight. Shaking his head in wonder at the strangeness of it all, he went 
towards the garden where he had left his horse, tethered to a tree. Suddenly, 
a large rose bush caught his eye.
   Remembering his promise to Beauty, he bent down to pick a rose. lnstantly, 
out of the rose garden, sprang a horrible beast, wearing splendid clothes. Two
bloodshot eyes, gleaming angrily, glared at him and a deep, terrifying voice 
growled: "Ungrateful man! I gave you shelter, you ate at my table and slept in 
my own bed, but now all the thanks I get is the theft of my favourite flowers!
I shall put you to death for this slight!" Trembling with fear, the merchant 
fell on his knees before the Beast.
   "Forgive me! Forgive me! Don't kill me! I'll do anything you say! The rose 
wasn't for me, it was for my daughter Beauty. I promised to bring her back a 
rose from my journey!" The Beast dropped the paw it had clamped on the unhappy
merchant.
   "I shall spare your life, but on one condition, that you bring me your 
daughter!" The terror-stricken merchant, faced with certain death if he did 
not obey, promised that he would do so. When he reached home in tears, his 
three daughters ran to greet him. After he had told them of his dreadful 
adventure, Beauty put his mind at rest immediately.
   "Dear father, I'd do anything for you! Don't worry, you'll be able to keep 
your promise and save your life! Take me to the castle. I'll stay there in 
your place!" The merchant hugged his daughter.
   "I never did doubt your love for me. For the moment I can only thank you 
for saving my life." So Beauty was led to the castle. The Beast, however, had 
quite an unexpected greeting for the girl. Instead of menacing doom as it had 
done with her father, it was surprisingly pleasant. 
   In the beginning, Beauty was frightened of the Beast, and shuddered at the 
sight of it. Then she found that, in spite of the monster's awful head, her 
horror of it was gradually fading as time went by. She had one of the finest 
rooms in the Castle, and sat for hours, embroidering in front of the fire. And
the Beast would sit, for hours on end, only a short distance away, silently 
gazing at her. Then it started to say a few kind words, till in the end, 
Beauty was amazed to discover that she was actually enjoying its conversation.
The days passed, and Beauty and the Beast became good friends. Then one day, 
the Beast asked the girl to be his wife.                  .-~
   Taken by surprise, Beauty did not know what to say. Marry such an ugly 
monster? She would rather die! But she did not want to  hurt the feelings of 
one who, after all, had been kind to her. And she remembered too that she owed
it her own life as well as her father's.
   "I really can't say yes," she began shakily. "I'd so much like to . . ." 
The Beast interrupted her with an abrupt gesture.
   "I quite understand! And I'm not offended by your refusal!" Life went on as
usual, and nothing further was said. One day, the Beast presented Beauty with 
a magnificent magic mirror. When Beauty peeped into it, she could see her 
family, far away.
   "You won't feel so lonely now," were the words that accompanied the gift. 
Beauty stared for hours at her distant family. Then she began to feel worried.
One day, the Beast found her weeping beside the magic mirror.
   "What's wrong?" he asked, kindly as always.                        
   "My father is gravely ill and close to dying! Oh, how I wish I could see 
him again, before it's too late!" But the Beast only shook its head.
   "No! You will never leave this castle!" And off it stalked in a rage. 
However, a little later, it returned and spoke solemnly to the girl._
   "If you swear that you will return here in seven days time, I'll let you go
and visit your father!" Beauty threw herself at the Beast's feet in delight.
   "I swear! I swear I will! How kind you are! You've made a loving daughter 
so happy!" In reality, the merchant had fallen ill from a broken heart at 
knowing his daughter was being kept prisoner. When he embraced her again, he 
was soon on the road to recovery. Beauty stayed beside him for hours on end, 
describing her life at the Castle, and explaining that the Beast was really 
good and kind. The days flashed past, and at last the merchant was able to 
leave his bed. He was completely well again. Beauty was happy at last. 
However, she had failed to notice that seven days had gone by.
   Then one night she woke from a terrible nightmare. She had dreamt that the 
Beast was dying and calling for her, twisting in agony. 
   "Come back! Come back to me!" it was pleading. The solem  promise she had 
made drove her to leave home immediately. 
   "Hurry! Hurry, good horse!" she said, whipping her steed onwards towards 
the castle, afraid that she might arrive too late. She rushed up the stairs, 
calling, but there was no reply. Her heart in her mouth, Beauty ran into the 
garden and there crouched the Beast, its eyes shut, as though dead. Beauty 
threw herself at it and hugged it tightly.
   "Don't die! Don't die! I'll marry you . . ." At these words, a miracle took
place. The Beast's ugly snout turned magically into the face of a handsome 
young man.
    "How I've been longing for this moment!" he said. "I was suffering in 
silence, and couldn't tell my frightful secret. An evil witch turned me into a
monster and only the love of a maiden willing to accept me as I was, could 
transform me back into my real self. My dearest! I'll be so happy if you'll 
marry me . . ."
   The wedding took place shortly after and, from that day on, the young 
Prince would have nothing but roses in his gardens. And that's why, to this 
day, the castle is known as the Castle of the Rose.
 Mr. Rabbit sat on his front porch rocking, eating a great big carrot, 
and looking.

    "Looks like Sly Fox coming down the road," he said to himself, walking 
to the end of the porch. Shading his eyes with his paws, he exclaimed, "It 
is Sly Fox." 

    "Good morning Mr. Rabbit," cried Sly Fox, as he walked across the yard. 
"Good morning," replied Mr. Rabbit, a slight frown on his face. 

    "Well," said Sly Fox, "as I haven't seen you in so long a time, thought 
I would stop and chat a while." 

    Mr. Rabbit could not be rude in his own home, even to an enemy, so he 
offered Sly Fox a seat on the porch. 

    "Take a chair," he said politely.   But Sly Fox did not stay long, and as 
he was leaving, he asked: "Mr. Rabbit, my mother is having a good dinner 
tonight. Won't you, Mrs. Rabbit, and your three little rabs come to dinner 
with me?" 

    Oh, thought Mr. Rabbit, he knows about my little rabs and wants to take 
us off to eat us. He pretended to be disappointed as he replied: "Sorry, Sly 
Fox, we have an engagement for today, but if you want us we can come 
tomorrow." 

    At this Sly Fox chuckled inwardly, and readily agreed to come for them 
the next day. Wishing Mr. Rabbit "Good day", he trotted on down the road 
toward his home. 

    As soon as he was out of sight, Mr. Rabbit ran into his house and called 
Mrs. Rabbit. "Get all our things together," he said, "and put rubber boots 
on our little rabs. We have to move quickly to the Piney Woods across the 
brook. Old Sly Fox has found our home and will destroy us." 

    In no time at all the Rabbit family had moved, and the little rabs were 
delighted with their new home. A woodland of towering pines it was, the 
ground covered with pine needles which made a soft carpeting. The wind made 
music in the pine trees, birds sang, and the fragrance of flowers filled the 
air. They found a huge hollow tree where Mr. Rabbit burrowed deep and made 
them a cozy home. Squirrels had left nuts hidden around in the old tree. 
Owls hooted throughout the night, crickets chirped merrily. 

    Next morning old Sly Fox knocked on the door where he had left Mr. 
Rabbit. Mrs. Hedgehog answered the door. "Good morning, Mrs. Hedgehog. Is 
Mr. Rabbit in?" inquired Sly Fox with a wicked grin and a cunning look in 
his eyes. 

    "No," replied Mrs. Eedgehog, none too cordially. "The Rabbit family 
moved to parts unknown right after you left yesterday." 

    "Ah," exclaimed old Sly Fox, "Mr. Rabbit and family were going to have 
dinner with me. My mother has planned a real feast. Why don't you come and 
enjoy it with us?" 

    "Oh," replied Mrs. Hedgehog, smacking her lips and thinking of all the 
goodies, "I have just moved in and there is so much to do! Why not let it go 
until tomorrow?" 

    "Do you like nice young grasshoppers?" asked Sly Fox softly. 

    "Do I? Nothing so good as tender young grasshoppers," answered Mrs. 
Hedgehog, fairly dribbling at the mouth at the thought of such a dainty. 

    "Well," said Sly Fox, "we pass a field where there are any number of 
them. Come get in this sack, and when I stop in the field we will open the 
sack and rake in all of them we want. Mother will bake them with apples and 
they will be deilicious!" This was too much for greedy Mrs. Hedgehog to 
resist, so in the sack she went. Sly Fox with a grin grabbed the sack, threw 
it over his shoulder and trotted toward home.     After going a long way, Mrs. 
Hedgehog became suspicious and cried, "How long before we reach that field 
of grasshoppers?" 

    "Why, you silly, greedy hedgehog, there is no field of grasshoppers for 
you. I am going to eat you for my dinner. It's you with apple dumplings that 
my mother will bake." 

    Every hair on Mrs. Hedgehog's head stood on end with fright. Oh, how 
foolish she had been! Her greed had trapped her. If only she had stayed home 
and straightened her house and cooked her own dinner, she would not have 
been in this sack to be eaten by Sly Fox. Greediness never pays, she thought 
to herself. 

    Sly Fox became tired, and as a slight rain had begun to fall, he looked 
for a dry place to sit down. Throwing the sack to the ground and chuckling 
at the thought of sitting on Mrs. Hedgehog, he dropped heavily upon the 
sack. 

    "Wow, Wow!" he cried, jumping quickly up, for Mrs. Hedgehog shot her 
sharp quills into him with all her might. 

    Sly Fox ran to and fro trying to pull out the quills, but they had gone 
too deep. Home he ran, screaming to his mother. Old Mother Fox threw him 
over a log and began pulling out the quills, at the same time calling to a 
neighbor fox to bring some honey to put on the places where the quills had 
been. 

    Mrs. Hedgehog crawled out of the bag and began walking slowly toward 
home. She thought to herself that never again would she be so greedy and 
allow herself to be fooled by Sly Fox or any one else. 

    Meanwhile, Mr. Rabbit and family were living happily in Piney Woods. The 
little rabs played on the crystal clear brook that ran through the woods, 
wading, sailing little leaf boats, and trying to catch the silvery minnows 
darting here and there. 

    Late one evening Papa and Mama Rabbit were sitting before the cozy fire 
talking. Papa Rabbit had on his house robe and bedroom slippers, reading the 
newspaper. Every now and then he looked over his spectacles lovingly at 
dainty little Mama Rabbit, dressed in a flowered housecoat and red slippers 
and knitting little socks for the little rabs. 

    "Sniff! Sniff! Sniff!" came suddenly to their ears. 

    "Sly Fox!" whispered Papa Rabbit, his face now full of concern and 
alarm. 

    "Yes," agreed Mama Rabbit, her voice trembling with fright. 

    "Go cover the little rabs with straw and tell them to be very, very 
quiet," instructed Papa Rabbit. 

    Mrs. Rabbit quickly covered the little rabs and cautioned them to be as 
quiet as mice. Since they were well behaved and obedient little rabs, they 
did just as their mother told them. 

    "I left my big stick beside the old oak tree," cried Papa Rabbit under 
his breath. "What shall we do?" 

    "Sniff! Sniff! Sniff!" went Sly Fox again, scratching up the earth by 
the old hollow tree as he began to dig furiously. The poor little Rabbit 
family sat still and frightened, their hearts thumping, their paws shaking, 
and their eyes bulging with panic. Suddenly in the distance they heard the 
"Toot! Toot!Toot!" of horns, and the "Woof! Woof! Woof!" of barking dogs. 

    Papa Rabbit whispered, "Fox hunters!" as his heart gave a bound of 
relief. 

    Nearer and nearer came the baying of the hounds and the music of the 
horns. Old Sly Fox was so busily digging that he failed to hear at first, 
but suddenly he stopped digging, and threw back his ears to listen. Then he 
quickly jumped away from the log where the Rabbit family lived and started 
running. 

    But the hounds were right after him, baying loudly with all their might. 
The horses' feet beat out an excited rhythm as the red-coated fox hunters 
urged them on in the chase. Up hill, over the meadows they ran. 

    Sly Fox was now running for his life, but the dogs were getting closer 
and closer. He jumped across the brook and spied a hole among some bushes. 
Into this he slid, and as the dogs went down the side of the stream of water 
before they jumped across they lost his scent. Sly Fox quickly ran out of 
the hole and took off in the opposite direction from the way the dogs were 
going. He had been so frightened and so near death that he resolved to 
himself never to bother the Rabbit family again. 

    Meanwhile, when Papa Rabbit had heard the hounds start the chase, he 
turned to Mama Rabbit and cried, "Safe at last! Call our little rabs for 
prayers of thanksgiving and praise to our Father which art in heaven." 

    After prayers, Mama Rabbit hustled about making mint tea for her and 
Papa Rabbit, and hot chocolate piled high with whipped cream for the little 
rabs. After that time they Lived happily among the great whispering pines, 
never bothered by old Sly Fox.
Once upon a time . . . a woodcutter lived happily with his wife in a pretty
little log cabin in the middle of a thick forest. Each morning he set off 
singing to work, and when he came home in the evening, a plate of hot steaming 
soup was always waiting for him. 
   One day, however, he had a strange surprise. He came upon a big fir tree 
with strange open holes on the trunk. It looked somehow different from the 
other trees, and just as he was about to chop it down, the alarmed face of an 
elf popped out of a hole.
   "What's all this banging?" asked the elf. "You're not thinking of cutting 
down this tree, are you? It's my home. I live here!" The woodcutter dropped 
his axe in astonlshment.
   "Well, I . . ." he stammered.
   "With all the other trees there are in this forest, you have to pick this 
one. Lucky I was in, or I would have found myself homeless."
   Taken aback at these words, the woodcutter qulckly recovered, for after all
the elf was quite tiny, while he himself was a big hefty chap, and he boldly 
replied: "I'll cut down any tree I like, so . . ." 
   "All right! All right!" broke in the elf. "Shall we put it this way: if you
don't cut down this tree, I grant you three wishes. Agreed?" The woodcutter 
scratched his head. 
   "Three wishes, you say? Yes, I agree." And he began to hack at another 
tree. As he worked and sweated at his task, the woodcutter kept thinking about
the magic wishes. 
   "I'll see what my wife thinks..."
   The woodcutter's wife was busily cleaning a pot outside the house when her 
husband arrived. Grabbing her round the waist, he twirled her in delight.
   "Hooray! Hooray! Our luck is in!" 
   The woman could not understand why her husband was so pleased with himself 
and she shrugged herself free. Later, however, over a glass of fine wine at 
the table, the woodcutter told his wife of his meeting with the elf, and she 
too began to picture the wonderful things that the elf's three wishes might 
give them. The woodcutter's wife took a first sip of wine from her husband's 
glass.
   "Nice," she said, smacking her lips. "I wish I had a string of sausages to 
go with it, though..."
   Instantly she bit her tongue, but too late. Out of the air appeared the 
sausages while the woodcutter stuttered with rage.
   ". . . what have you done! Sausages . . . What a stupid waste of a wish! 
You foollsh woman. I wish they would stick up your nose!" No sooner sald than
done. For the sausages leapt up and stuck fast to the end of the woman's nose.
This time, the woodcutter's wife flew into a rage.
   "You idiot, what have you done? With all the things we could have wished 
for . . ." The mortified woodcutter, who had just repeated his wife's own 
mistake, exclaimed:
   "I'd chop . . ." Luckily he stopped himself in time, realizing with horror 
that he'd been on the point of having his tongue chopped off. As his wife 
complained and blamed him, the poor man burst out laughing.
   "If only you knew how funny you look with those sausages on the end of your
nose!" Now that really upset the woodcutter's wife. She hadn't thought of her 
looks. She tried to tug away the sausages but they would not budge. She pulled 
again and again, but in vain. The sausages were firmly attached to her nose. 
Terrified, she exclaimed: "They'll be there for the rest of my life!"
   Feeling sorry for his wife and wondering how he could ever put up with a 
woman with such an awkward nose, the woodcutter said: "I'll try." Grasping the
string of sausages, he tugged with all his might. But he simply pulled his 
wife over on top of him. The pair sat on the floor, gazing sadly at each other.
   "What shall we do now?" they said, each thinking the same thought.
   "There's only one thing we can do . . ." ventured the woodcutter's wife 
timidly.
   "Yes, I'm afraid so . . ." her husband sighed, remembering their dreams of 
riches, and he bravely wished the third and last wish "I wish the sausages 
would leave my wife's nose."
   And they did. Instantly, husband and wife hugged each other tearfully, 
saying "Maybe we'll be poor, but we'll be happy again!"
   That evening, the only reminder of the woodcutter's meeting with the elf 
was the string of sausages. So the couple fried them, gloomily thinking of 
what that meal had cost them.
 

 Authorship attribution supported by statistical or computational methods has a long history
starting from 19th century and marked by the seminal study of Mosteller and Wallace (1964)
on the authorship of the disputed Federalist Papers. During the last decade, this scientific field
has been developed substantially taking advantage of research advances in areas such as
machine learning, information retrieval, and natural language processing. The plethora of
available electronic texts (e.g., e-mail messages, online forum messages, blogs, source code,
etc.) indicates a wide variety of applications of this technology provided it is able to handle
short and noisy text from multiple candidate authors. In this paper, a survey of recent
advances of the automated approaches to attributing authorship is presented examining their
characteristics for both text representation and text classification. The focus of this survey is
on computational requirements and settings rather than linguistic or literary issues. We also
discuss evaluation methodologies and criteria for authorship attribution studies and list open
questions that will attract future work in this area. 
The main idea behind statistically or computationally-supported authorship attribution is that
by measuring some textual features we can distinguish between texts written by different
authors. The first attempts to quantify the writing style go back to 19th century, with the
pioneering study of Mendenhall (1887) on the plays of Shakespeare followed by statistical
studies in the first half of the 20th century by Yule (1938; 1944) and Zipf (1932). Later, the
detailed study by Mosteller and Wallace (1964) on the authorship of ‘The Federalist Papers’
(a series of 146 political essays written by John Jay, Alexander Hamilton, and James
Madison, twelve of which claimed by both Hamilton and Madison) was undoubtedly the most
influential work in authorship attribution. Their method was based on Bayesian statistical
analysis of the frequencies of a small set of common words (e.g., ‘and’, ‘to’, etc.) and
produced significant discrimination results between the candidate authors.
Essentially, the work of Mosteller and Wallace (1964) initiated non-traditional
authorship attribution studies, as opposed to traditional human expert-based methods. Since
then and until the late 1990s, research in authorship attribution was dominated by attempts to
define features for quantifying writing style, a line of research known as ‘stylometry’
(Holmes, 1994; Holmes, 1998). Hence, a great variety of measures including sentence length,
word length, word frequencies, character frequencies, and vocabulary richness functions had
been proposed. Rudman (1998) estimated that nearly 1,000 different measures had been
proposed that far. The authorship attribution methodologies proposed during that period were
computer-assisted rather than computer-based, meaning that the aim was rarely at developing
a fully-automated system. In certain cases, there were methods achieved impressive
preliminary results and made many people think that the solution of this problem was too
close. The most characteristic example is the CUSUM (or QSUM) technique (Morton &
Michealson, 1990) that gained publicity and was accepted in courts as expert evidence.
However, the research community heavily criticized it and considered it generally unreliable
(Holmes & Tweedie, 1995). Actually, the main problem of that early period was the lack of 
2
objective evaluation of the proposed methods. In most of the cases, the testing ground was
literary works of unknown or disputed authorship (e.g., the Federalist case), so the estimation
of attribution accuracy was not even possible. The main methodological limitations of that
period concerning the evaluation procedure were the following:
• The textual data were too long (usually including entire books) and probably not
stylistically homogeneous.
• The number of candidate authors was too small (usually 2 or 3).
• The evaluation corpora were not controlled for topic.
• The evaluation of the proposed methods was mainly intuitive (usually based on
subjective visual inspection of scatterplots).
• The comparison of different methods was difficult due to lack of suitable
benchmark data.
Since the late 1990s, things have changed in authorship attribution studies. The vast
amount of electronic texts available through Internet media (emails, blogs, online forums, etc)
increased the need for handling this information efficiently. This fact had a significant impact
in scientific areas such as information retrieval, machine learning, and natural language
processing (NLP). The development of these areas influenced authorship attribution
technology as described below:
• Information retrieval research developed efficient techniques for representing and
classifying large volumes of text.
• Powerful machine learning algorithms became available to handle multidimensional
and sparse data allowing more expressive representations. Moreover,
standard evaluation methodologies have been established to compare different
approaches on the same benchmark data.
• NLP research developed tools able to analyze text efficiently and providing new
forms of measures for representing the style (e.g., syntax-based features).
More importantly, the plethora of available electronic texts revealed the potential of
authorship analysis in various applications (Madigan, Lewis, Argamon, Fradkin, & Ye, 2005)
in diverse areas including intelligence (e.g., attribution of messages or proclamations to
known terrorists, linking different messages by authorship) (Abbasi & Chen, 2005), criminal
law (e.g., identifying writers of harassing messages, verifying the authenticity of suicide
notes) and civil law (e.g., copyright disputes) (Chaski, 2005; Grant, 2007), computer forensics
(e.g., identifying the authors of source code of malicious software) (Frantzeskou, Stamatatos,
Gritzalis, & Katsikas, 2006), in addition to the traditional application to literary research (e.g.,
attributing anonymous or disputed literary works to known authors) (Burrows, 2002; Hoover,
2004a). Hence, (roughly) the last decade can be viewed as a new era of authorship analysis
technology, this time dominated by efforts to develop practical applications dealing with realworld
texts (e.g., e-mails, blogs, online forum messages, source code, etc.) rather than solving
disputed literary questions. Emphasis is now given to the objective evaluation of the proposed
methods as well as the comparison of different methods based on common benchmark
corpora (Juola, 2004). In addition, factors playing a crucial role in the accuracy of the
produced models are examined, such as the training text size (Marton, Wu, & Hellerstein,
2005; Hirst & Feiguina, 2007), the number of candidate authors (Koppel, Schler, Argamon, &
Messeri, 2006), and the distribution of training texts over the candidate authors (Stamatatos,
2008).
In the typical authorship attribution problem, a text of unknown authorship is assigned to
one candidate author, given a set of candidate authors for whom text samples of undisputed
authorship are available. From a machine learning point-of-view, this can be viewed as a
multi-class single-label text categorization task (Sebastiani, 2002). This task is also called
authorship (or author) identification usually by researchers with a background in computer
science. Several studies focus exclusively on authorship attribution (Stamatatos, Fakotakis, &
Kokkinakis, 2001; Keselj, Peng, Cercone, & Thomas, 2003; Zheng, Li, Chen, & Huang, 
3
2006) while others use it as just another testing 
This paper presents a survey of the research advances in this area during roughly the last
decade (earlier work is excellently reviewed by Holmes (1994; 1998)) emphasizing
computational requirements and settings rather than linguistic or literary issues. First, in
Section 2, a comprehensive review of the approaches to quantify the writing style is
presented. Then, in Section 3, we focus on the authorship identification problem (as described
above). We propose the distinction of attribution methodologies according to how they handle
the training texts, individually or cumulatively (per author), and examine their strengths and
weaknesses across several factors. In Section 4, we discuss the evaluation criteria of
authorship attribution methods while in Section 5 the conclusions drawn by this survey are
summarized and future work directions in open research issues are indicated.
2. Stylometric Features
Previous studies on authorship attribution proposed taxonomies of features to quantify the
writing style, the so called style markers, under different labels and criteria (Holmes, 1994;
Stamatatos, Fakotakis, & Kokkinakis, 2000; Zheng, et al., 2006). The current review of text
representation features for stylistic purposes is mainly focused on the computational
requirements for measuring them. First, lexical and character features consider a text as a
mere sequence of word-tokens or characters, respectively. Note that although lexical features
are more complex than character features, we start with them for the sake of tradition. Then,
syntactic and semantic features require deeper linguistic analysis, while application-specific
features can only be defined in certain text domains or languages. The basic feature categories
and the required tools and resources for their measurement are shown in Table 1. Moreover,
various feature selection and extraction methods to form the most appropriate feature set for a
particular corpus are discussed.
2.1 Lexical Features
A simple and natural way to view a text is as a sequence of tokens grouped into sentences,
each token corresponding to a word, number, or a punctuation mark. The very first attempts
to attribute authorship were based on simple measures such as sentence length counts and
word length counts (Mendenhall, 1887). A significant advantage of such features is that they
can be applied to any language and any corpus with no additional requirements except the
availability of a tokenizer (i.e., a tool to segment text into tokens). However, for certain
natural languages (e.g., Chinese) this is not a trivial task. In case of using sentential
information, a tool that detects sentence boundaries should also be available. In certain text
domains with heavy use of abbreviations or acronyms (e.g., e-mail messages) this procedure
may introduce considerable noise in the measures.
The vocabulary richness functions are attempts to quantify the diversity of the
vocabulary of a text. Typical examples are the type-token ratio V/N, where V is the size of the 
4
TABLE 1. Types of stylometric features together with computational tools and resources
required for their measurement (brackets indicate optional tools).
vocabulary (unique tokens) and N is the total number of tokens of the text, and the number of
hapax legomena (i.e., words occurring once) (de Vel, Anderson, Corney, & Mohay, 2001).
Unfortunately, the vocabulary size heavily depends on text-length (as the text-length
increases, the vocabulary also increases, quickly at the beginning and then more and more
slowly). Various functions have been proposed to achieve stability over text-length, including
K (Yule, 1944), and R (Honore, 1979), with questionable results (Tweedie & Baayen, 1998).
Hence, such measures are considered unreliable to be used alone.
The most straightforward approach to represent texts is by vectors of word frequencies. The
vast majority of authorship attribution studies are (at least partially) based on lexical features
to represent the style. This is also the traditional bag-of-words text representation followed by
researchers in topic-based text classification (Sebastiani, 2002). That is, the text is considered
as a set of words each one having a frequency of occurrence disregarding contextual
information. However, there is a significant difference in style-based text classification: the
most common words (articles, prepositions, pronouns, etc.) are found to be among the best
features to discriminate between authors (Burrows, 1987; Argamon & Levitan, 2005). Note
that such words are usually excluded from the feature set of the topic-based text classification
methods since they do not carry any semantic information and they are usually called
‘function’ words. As a consequence, style-based text classification using lexical features
require much lower dimensionality in comparison to topic-based text classification. In other
words, much less words are sufficient to perform authorship attribution (a few hundred
words) in comparison to a thematic text categorization task (several thousand words). More
importantly, function words are used in a largely unconscious manner by the authors and they
are topic-independent. Thus, they are able to capture pure stylistic choices of the authors
across different topics.
The selection of the specific function words that will be used as features is usually based
on arbitrary criteria and requires language-dependent expertise. Various sets of function
words have been used for English but limited information was provided about the way they
have been selected: Abbasi and Chen (2005) reported a set of 150 function words; Argamon,
Saric, and Stein (2003) used a set of 303 words; Zhao and Zobel (2005) used a set of 365
function words; 480 function words were proposed by Koppel and Schler (2003); another set
of 675 words was reported by Argamon, Whitelaw, Chase, Hota, Garg, and Levitan (2007).
A simple and very successful method to define a lexical feature set for authorship
attribution is to extract the most frequent words found in the available corpus (comprising all
the texts of the candidate authors). Then, a decision has to be made about the amount of the
frequent words that will be used as features. In the earlier studies, sets of at most 100 frequent
words were considered adequate to represent the style of an author (Burrows, 1987; Burrows,
1992). Another factor that affects the feature set size is the classification algorithm that will
be used since many algorithms overfit the training data when the dimensionality of the
problem increases. However, the availability of powerful machine learning algorithms able to
deal with thousands of features, like support vector machines (Joachims, 1998), enabled
researchers to increase the feature set size of this method. Koppel, Schler, and BonchekDokow
(2007) used the 250 most frequent words while Stamatatos (2006a) extracted the
1,000 most frequent words. On a larger scale, Madigan, et al., (2005) used all the words that
appear at least twice in the corpus. Note that the first dozens of most frequent words of a
corpus are usually dominated by closed class words (articles, prepositions etc.) After a few
hundred words, open class words (nouns, adjectives, verbs) are the majority. Hence, when the
dimensionality of this representation method increases, some content-specific words may also
be included in the feature set.
Despite the availability of a tokenizer, word-based features may require additional tools
for their extraction. This would involve from simple routines like conversion to lowercase to
more complex tools like stemmers (Sanderson & Guenter, 2006), lemmatizers (Tambouratzis,
Markantonatou, Hairetakis, Vassiliou, Carayannis, & Tambouratzis, 2004; Gamon, 2004), or
detectors of common homographic forms (Burrows, 2002). Another procedure used by van
Halteren (2007) is to transform words into an abstract form. For example, the Dutch word
‘waarmaken’ is transformed to ‘#L#6+/L/ken’, where the first L indicates low frequency, 6+ 
indicates the length of the token, the second L a lowercase token, and ‘ken’ are its last three
characters.
The bag-of-words approach provides a simple and efficient solution but disregards wordorder
(i.e., contextual) information. For example, the phrases ‘take on’, ‘the second take’ and
‘take a bath’ would just provide three occurrences of the word ‘take’. To take advantage of
contextual information, word n-grams (n contiguous words aka word collocations) have been
proposed as textual features (Peng, et al., 2004; Sanderson & Guenther, 2006; CoyotlMorales,
Villaseñor-Pineda, Montes-y-Gómez, & Rosso, 2006). However, the classification
accuracy achieved by word n-grams is not always better than individual word features
(Sanderson & Guenther, 2006; Coyotl-Morales, et al., 2006). The dimensionality of the
problem following this approach increases considerably with n to account for all the possible
combinations between words. Moreover, the representation produced by this approach is very
sparse, since most of the word combinations are not encountered in a given (especially short)
text making it very difficult to be handled effectively by a classification algorithm. Another
problem with word n-grams is that it is quite possible to capture content-specific information
rather than stylistic information (Gamon, 2004).
From another point of view, Koppel and Schler (2003) proposed various writing error
measures to capture the idiosyncrasies of an author’s style. To that end, they defined a set of
spelling errors (e.g., letter omissions and insertions) and formatting errors (e.g., all caps
words) and they proposed a methodology to extract such measures automatically using a spell
checker. Interestingly, human experts mainly use similar observations in order to attribute
authorship. However, the availability of accurate spell checkers is still problematic for many
natural languages. 
According to this family of measures, a text is viewed as a mere sequence of characters. That
way, various character-level measures can be defined, including alphabetic characters count,
digit characters count, uppercase and lowercase characters count, letter frequencies,
punctuation marks count, etc. (de Vel, et al., 2001; Zheng, et al., 2006). This type of
information is easily available for any natural language and corpus and it has been proven to
be quite useful to quantify the writing style (Grieve, 2007).
A more elaborate, although still computationally simplistic, approach is to extract
frequencies of n-grams on the character-level. For instance, the character 4-grams of the
beginning of this paragraph would be1
: |A_mo|, |_mor|, |more|, |ore_|, |re_e|, etc. This
approach is able to capture nuances of style including lexical information (e.g., |_in_|, |text|),
hints of contextual information (e.g., |in_t|), use of punctuation and capitalization, etc.
Another advantage of this representation is its ability to be tolerant to noise. In cases where
the texts in question are noisy containing grammatical errors or making strange use of
punctuation, as it usually happens in e-mails or online forum messages, the character n-gram
representation is not affected dramatically. For example, the words ‘simplistic’ and
‘simpilstc’ would produce many common character trigrams. On the other hand, these two
words would be considered different in a lexically-based representation. Note that in stylebased
text categorization such errors could be considered personal traits of the author (Koppel
& Schler, 2003). This information is also captured by character n-grams (e.g., in the
uncommon trigrams |stc| and |tc_|). Finally, for oriental languages where the tokenization
procedure is quite hard, character n-grams offer a suitable solution (Matsuura & Kanada,
2000). As can be seen in Table 1, the computational requirements of character n-gram
features are minimal. 
Note that, as with words, the most frequent character n-grams are the most important
features for stylistic purposes. The procedure of extracting the most frequent n-grams is
language-independent and requires no special tools. However, the dimensionality of this
representation is considerably increased in comparison to the word-based approach 
(Stamatatos, 2006a; Stamatatos, 2006b). This happens because character n-grams capture
redundant information (e.g., |and_|, |_and|) and many character n-grams are needed to
represent a single long word.
The application of this approach to authorship attribution has been proven quite
successful. Kjell (1994) first used character bigrams and trigrams to discriminate the
Federalist Papers. Forsyth and Holmes (1996) found that bigrams and character n-grams of
variable-length performed better than lexical features in several text classification tasks
including authorship attribution. Peng, Shuurmans, Keselj, & Wang (2003), Keselj et al.
(2003), and Stamatatos (2006b) reported very good results using character n-gram
information. Moreover, one of the best performing algorithms in an authorship attribution
competition organized in 2004 was also based on a character n-gram representation (Juola,
2004; Juola, 2006). Likewise, a recent comparison of different lexical and character features
on the same evaluation corpora (Grieve, 2007) showed that character n-grams were the most
effective measures (outperformed in the specific experiments only by a combination of
frequent words and punctuation marks).
An important issue of the character n-gram approach is the definition of n, that is, how
long should the strings be. A large n would better capture lexical and contextual information
but it would also better capture thematic information. Furthermore, a large n would increase
substantially the dimensionality of the representation (producing hundreds of thousands of
features). On the other hand, a small n (2 or 3) would be able to represent sub-word (syllablelike)
information but it would not be adequate for representing the contextual information. It
has to be underlined that the selection of the best n value is a language-dependent procedure
since certain natural languages (e.g., Greek, German) tend to have long words in comparison
to English. Therefore, probably a larger n value would be more appropriate for such
languages in comparison to the optimal n value for English. The problem of defining a fixed
value for n can be avoided by the extraction of n-grams of variable-length (Forsyth &
Holmes, 1996; Houvardas & Stamatatos, 2006). Sanderson and Guenter (2006) described the
use of several sequence kernels based on character n-grams of variable-length and the best
results for short English texts were achieved when examining sequences of up to 4-grams.
Moreover, various Markov models of variable order have been proposed for handling
character-level information (Khmelev & Teahan, 2003a; Marton, et al., 2005). Finally, Zhang
and Lee (2006) constructed a suffix tree representing all possible character n-grams of
variable-length and then extracted groups of character n-grams as features.
A quite particular case of using character information is the compression-based
approaches (Benedetto, Caglioti, & Loreto, 2002; Khmelev & Teahan, 2003a; Marton, et al.,
2005). The main idea is to use the compression model acquired from one text to compress
another text, usually based on off-the-shelf compression programs. If the two texts are written
by the same author, the resulting bit-wise size of the compressed file will be relatively low.
Such methods do not require a concrete representation of text and the classification algorithm
incorporates the quantification of textual properties. However, the compression models that
describe the characteristics of the texts are usually based on repetitions of character sequences
and, as a result, they can capture sub-word and contextual information. In that sense, they can
be considered as character-based methods. 
A more elaborate text representation method is to employ syntactic information. The idea is
that authors tend to use similar syntactic patterns unconsciously. Therefore, syntactic
information is considered more reliable authorial fingerprint in comparison to lexical
information. Moreover, the success of function words in representing style indicates the
usefulness of syntactic information since they are usually encountered in certain syntactic
structures. On the other hand, this type of information requires robust and accurate NLP tools
able to perform syntactic analysis of texts. This fact means that the syntactic measure
extraction is a language-dependent procedure since it relies on the availability of a parser able 
In a similar framework, tools that perform partial parsing can be used to provide
syntactic features of varying complexity (Luyckx & Daelemans, 2005; Uzuner & Katz, 2005;
Hirst & Feiguina, 2007). Partial parsing is between text chunking and full parsing and can
handle unrestricted text with relatively high accuracy. Hirst and Feiguina (2007) transformed
the output of a partial parser into an ordered stream of syntactic labels, for instance the
analysis of the phrase ‘a simple example’ would produce the following stream of labels: 
It should be clear by now, the more detailed the text analysis required for extracting
stylometric features, the less accurate (and the more noisy) the produced measures. NLP tools
can be applied successfully to low-level tasks, such as sentence splitting, POS tagging, text
chunking, partial parsing, so relevant features would be measured accurately and the noise in
the corresponding datasets remains low. On the other hand, more complicated tasks such as
full syntactic parsing, semantic analysis, or pragmatic analysis cannot yet be handled
adequately by current NLP technology for unrestricted text. As a result, very few attempts
have been made to exploit high-level features for stylometric purposes.
Gamon (2004) used a tool able to produce semantic dependency graphs but he did not
provide information about the accuracy of this tool. Two kinds of information were then
extracted: binary semantic features and semantic modification relations. The former
concerned number and person of nouns, tense and aspect of verbs, etc. The latter described
the syntactic and semantic relations between a node of the graph and its daughters (e.g., a
nominal node with a nominal modifier indicating location). Reported results showed that
semantic information when combined with lexical and syntactic information improved the
classification accuracy.
McCarthy, Lewis, Dufty, and McNamara (2006) described another approach to extract
semantic measures. Based on WordNet (Fellbaum, 1998) they estimated information about
synonyms and hypernyms of the words, as well as the identification of causal verbs.
Moreover, they applied latent semantic analysis (Deerwester, Dumais, Furnas, Landauer, &
Harshman, 1990) to lexical features in order to detect semantic similarities between words
automatically. However, there was no detailed description of the features and the evaluation
procedure did not clarify the contribution of semantic information in the classification model.
Perhaps the most important method of exploiting semantic information so far was
described by Argamon, et al. (2007). Inspired by the theory of Systemic Functional Grammar
(SFG) (Halliday, 1994) they defined a set of functional features that associate certain words
or phrases with semantic information. In more detail, in SFG the ‘CONJUNCTION’ scheme














This course of Artificial Intelligence is based on the motivation of creating machines that are intelligent and in some sense can make rational decisions on their own when faced with a problem.

MOTIVATION:
The motivation behind studying this field is manifold. Be it movies, books, or research & development in tech giants, we see a lot of work happening in this direction. The idea in itself, of machines thinking to solve a problem by themselves, is quite fascinating. This in turn makes us think what intelligence actually means in the said context. Humans use the brain to make decisions which is a complex organ and understanding its working to be able to mimic (to some extent) and maybe improve upon it in some tasks is a goal to aim for.

USE CASES:
Over the years the various areas where Artificial Intelligence has found use and made an improvement in human life are as follows   
1. Natural Language   artificial intelligence has made it possible for an individuals speech to be recognized and text to speech synthesis work.
2. Vision   Object and person recognition be it from pictures or videos has been made possible by artificial intelligence. Combined with natural language processing, it has improved the lives of visually challenged individuals with the help of various technologies like scene description, question answer based on visual data etc.
3. Robotics & Game Playing   Both vision & natural language processing when combined and used in robotics, give startling results. Along with automated robots and cars, there have been advances in computers playing and winning against world champions at multiple games such as chess and GO.

INTRODUCTION:
There is a need to quantify what it is we mean when we talk about responding like humans to situations. When we think about this, we need to make it clear as to what is rationally correct to do in a situation. An interesting point to note here is that rational thinking and how humans react to situations are two distinct things. Therefore, there has been a divided opinion over how machines are to be made intelligent. Are they supposed to act like humans? Or are they supposed to take the ideally rational path? Well discuss the two one by one.

Making machines more like humans   
The great computer scientist and mathematician Alan Turing devised a system for measuring how close a machine is to responding like humans. According to the Turing Test, a machine can be said to be capable of thinking like human beings if, on interaction with a human, it is able to respond in a manner that is indistinguishable to how a human might have responded to the same set of situations/questions. However, even though this test remains relevant after all these years, it is believed that studying the underlying principles that lead to the way humans think is more important than just trying to duplicate the process.

Making rational machines   
To be succinct, rational thinking simply means maximizing expected utility. And making machines rational in a sense is a more objective goal since there is a fixed definition that can be agreed upon. Categorizing a decision as rational depends on 4 basic factors:
The way we define what success for a task means, what the decision making entity knows about the environment, the possible paths or actions that can be taken by the said entity, what all input has been received by the decision making entity till now, so that it can base, its decisions upon those.

Based on what the outcome of a particular action/decision is, we can express a goal as that outcome which has maximum utility for us based on the measure that we use for success.

Agents and Environments:
On a basic level, we consider an agent to be an entity that receives inputs or percepts from the environment with the help of sensors and acts upon the said environment.
Note that an agents chosen action can depend on all the inputs that it has received so far but not on anything that it hasnt perceived.
Also, a world state encodes all the information about the environment in any given situation.

Rationality of an Agent: 
Rational agents are those that tend to make decisions that end up maximizing the expected utility as described above. The selection of such rational actions is dictated by the environment, the inputs received by the agent, and the possible set of actions available to the agent. Note that rational agents optimize expected utility which is different from perfection which maximizes actual utility.

Types of Agents:
We learn about two types of agents   reflex agents and planning agents.

Reflex agents tend to work in a greedy manner and take a decision based on the current input and dont think as to what might be the consequences of their actions in the future. They do not take into consideration the effect their actions would have on the world state they are in. Also, reflex agents can be rational in those scenarios where the problem posed to them has the inherent property that just reacting to the situation according to current inputs is sufficient to lead to an outcome of maximized utility.

Planning agents on the other hand tend to look into the possibilities as to what might happen should they take a certain decision. This gives rise to the concept of planning in an optimal or complete way. Complete planning would mean a certain plan being followed by an agent, which is certain to lead to a solution if it exists. Optimal planning on the other hand is a kind of complete planning (which means that it inherently includes reaching to the goal) which costs the least. For this, we need to introduce the idea of how we define cost in a certain world, but in general, we tend to want to solve a problem in as little expenditure as possible. Also, in order to be able to figure out what would happen when a set of actions is taken, the agent needs to know how the environment actually works. What state change happens when a certain step is taken. Without sufficient information in this regard, a planning agent would not be able to perform as expected. Another requirement is fixing a goal. A goal is necessary for a planning agent to be able to terminate its analysis of possible actions i.e. when a certain set of actions cause the world to reach a goal state, the work of the agent can be said to be done.

Planning vs. Replanning: A planning agent can work in either of two possible ways. It could either work out all the possibilities of actions that can be taken, decide a path (set of steps) that would lead to the goal state optimally, and only then start working on it. On the other hand, it could also start working sooner than that and just keep on replanning its route until it ends up in one of the goal states. So, it basically divides the entire problem of reaching the goal state into smaller problems, decides an optimal path for them, and ultimately ends up solving the overall problem if a solution exists.

Search Problems:
Reaching the goal state can be modeled as a search problem in which we try to find the path (optimal if possible) to the goal state.
Such a search problem has the following components, in general   
1. A state space (the states the world can be in)
2. A successor function (mapping of current state to the next state according to available actions)   an encoding of how the world works
3. A start state and a goal state.
A goal test is generally created for the agent to be able to check if the current state is a goal state or not. Note that it is important to consider a successor function that is in some sense compatible with the state space chosen to model the problem.

Modelling as a search problem:
As mentioned above, we simply model a real world problem as a search problem, so the models can vary. The level of abstraction that we deem right for our model is a crucial point of decision.

Search states:
They are DIFFERENT from the world states. A search state only keeps the details that are needed for planning a path for the problem under consideration. So depending upon the problem (goal), the amount of information contained in a search state varies.
E.g. In a game of PacMan, for the eat all dots problem we need to include booleans corresponding to all the dots and not just the number of uneaten dots left because to be able to plan optimally the agent would need to know where should the agent head next.

Representations of paths to goal states in a problem:

State Space Graph   A mathematical representation of a search problem.
Nodes are the world configurations that concern us for a given problem. Some of these nodes would satisfy the goal test and would be called goal nodes. (Stressing that they may be more than one in number). Note that since (some information of) states are being represented using nodes, all the states occur only once. (Unlike search trees). Edges represent the information obtained from the successor function defining how state to state transitions take place according to the different actions taken by the agent. Due to the extremely large combinatorial rise in the number of states as the world becomes more and more complex, it is not usually possible to be able to build such graphs in practice.

Search Tree   a tree that contains all possible sequences of actions and the corresponding consequences with the start state as the root node.
It is generally much bigger than even the state space graph as there may be multiple possible ways to reach the same state and there would exist a branch in the search tree for all such possible paths. Note that any node in a search tree represents a complete path in the corresponding state space graph (starting from the root of the search tree and going till the said node). While finding out the optimum path we try to construct the search tree on demand and as little at a time as possible.

Building a search tree incrementally: General Tree Search
Using the following algorithm we try to explore as little as possible of the giant search tree and still come up with a solution (path).
The algorithm:
1. Initialize the search tree with just the initial state of the problem.
2. Now begin a loop:
   2a. If there are no candidates for expansion left, simply return failure. (At any point of time, the candidates for expansion in a search tree are just the leaves of the tree. 
   2b. Choose any of the leaf nodes for expansion (according to the chosen strategy)
   2c. If the node contains the information of a goal state, return the corresponding solution (i.e. starting from the root node till this node (goal node)).
   2d. Else expand the node and add the resulting nodes to the search tree
3. End Loop

Two crucial things in the above algorithm are:
The Fringe   It stores all the candidates for expansion at any given time. Depending upon the implementation we may have all the predecessors of each element in the fringe so as to be able to trace the path using which we were able to reach that particular node.
Second is the Exploration strategy   This is the strategy that we depend upon to pick a node from the fringe in step 2b. Possible strategies include DFS, BFS, UCS, etc.

Various exploration strategies:
In general, there are four properties that we would want to analyze for a given search algorithm   completeness, optimality, time complexity, and space complexity. 
To be able to quantify these properties lets consider a search tree that has c children for all the nodes. Let d be the maximum depth of the search tree. Note that solutions can exist at various depths in this tree.

Depth First Search   As the name suggests we expand the deepest node first, from the candidates for expansion. Implementing this strategy involves using a stack to store the fringe nodes. In this way, with the help of the last in first out strategy, we will go deeper and deeper along one path, until it terminates and then after popping all those nodes from the stack, we start exploring alternative paths (provided we dont already have a solution). In this algorithm, we may come across multiple situations where the nodes under comparison are at equal depth, in which case we would need to break ties. How we break such ties can also cause a drastic change in the run time of our algorithm.
Properties of DFS:
Completeness   if we can somehow keep track of already occurred nodes and prevent loops, we would be able to say that this approach would lead to a complete planning.
Optimality   This algorithm is not optimal in the sense that since it goes as deep as possible starting from the left, we would just end up getting the leftmost solution irrespective of the cost (say the cost is in the form of the number of steps taken from the start state).
Time Complexity   In the worst case, the goal node could be present at the bottom right most end of the search tree in which case we might have to traverse the entire tree i.e. O(c^d) complexity.
Space Complexity   As mentioned above, we are using a stack to store the fringe, which means as we go deeper we keep on adding children for all the nodes that come up on the path, but we expand along only one of them. Hence, for d depth (in the worst case) and c children for all the nodes on that path, the space complexity would be O(dc).
 
Breadth First Search   As the name suggests we expand the shallowest node first, from the candidates for expansion. Implementation of the fringe in this algorithm is using a queue. In this way, utilizing the first in first out strategy, this algorithm first explores all the nodes closest to the current node and then goes on to the next level of the tree.
Properties of BFS:
Completeness   This algorithm is complete in nature i.e. if a solution exists, this algorithm will provide us with it.
Optimality   In general it is not said to be optimal. Even though it will lead to a solution with the minimum number of steps from the root, the cost of each edge is not always one and hence as the edge cost varies, an optimal solution using this approach is not guaranteed.
Time complexity   Again in the worst case the goal node may be in the bottom right corner of the tree in which case we would end up exploring all the nodes with a complexity of O(c^d).
Space complexity   We are using a queue to keep track of the fringe nodes here, so at any given time we store the nodes at the current level that have not yet been expanded along with the children of the nodes that are at the same level as the current node but have been expanded. This would roughly be O(c^d) in the worst case.

BFS vs DFS   a major advantage for the BFS approach if the solution is shallow and to the right of the search tree because via DFS, we might take a very long time to reach the goal.
However, if the goal is at the bottom left, DFS would greatly outperform BFS, as BFS would traverse through all the nodes above the goal before reaching it, whereas DFS would just traverse the goals ancestors.
If there are memory constraints, DFS would be preferred since we might run out of memory in the case of BFS, before we can actually reach the goal.
In general, if the cost is defined by just the number of actions and it is to be minimized, we would definitely prefer BFS over DFS.

Iterative Deepening   Exploiting the advantageous properties of both BFS (shallow solution quicker) and DFS (no memory problem).
In this algorithm, we run DFS but we cap the maximum depth that it goes to, to some constant. If we are unable to find a solution, we incrementally increase the depth cap and try to find a solution, performing DFS at every turn. This may seem to be very wasteful as we end up doing the computations for the shallow layers again and again. But it turns out, it still would be better because if we look at the work being done, typically the number of nodes in a layer is the sum of the number of nodes in all the previous layers. So, a lot of the work is being done in the last layer anyway.

Uniform Cost Search   This algorithm is useful in those scenarios where we care about the cost of the actions and it is not just about minimizing the number of actions but the overall cost.
Following this strategy, we implement the fringe using a priority queue where the priority of an added node is decided using the cumulative cost from the root to that node. We use this priority queue in a BFS fashion. This means that at any given point of time, we pick that node from the fringe that has the lowest cumulative cost till then. If we implement such a priority queue using a heap, we just have to take the root of the heap and expand it in the search tree. Whenever we find the solution it is bound to be the optimal one because we would have already gone through any paths that cost less than the final one we choose. If any other path were to lead to another goal, it would definitely cost more.
Properties of UCS:
Completeness   Since we are concerned with the cost as well and we choose the minimum one at every step, this algorithm is bound to lead us to the solution if there is one. (Assumptions being that the best solution has a finite cost and the edges all have positive costs).
Optimality   It will give us an optimal path as discussed above in the description.
Time complexity   Say the cheapest solution ends up being the one with cost C. Let the edge costs be at least e. Then the effective depth at which we must have found our solution would be C/e. This means it would be exponential in this effective depth with the base being the number of children c. Hence, O(c^(C/e)) would be the time complexity, as we would have explored all the paths with cost less than the optimal one.
Space Complexity   Here the fringe is implemented using a priority queue which at a time would include the nodes at the end of the boundary of the effective depth. This would lead to a space complexity of O(c^(C/e)) (= all nodes in the boundary of the effective depth level).
Drawbacks: It has no information to use, about the goal state. This causes it to just explore in all directions wherever it can find the smallest cost not caring whether it is actually approaching the goal with a step in that direction or not. This causes some useless computation which will be rectified using A* search below. There we would look at promising leads and not just basing our next step on the cheapest so far approach.

DFS, BFS, and UCS   What unifies them?
The only difference between the above algorithms is the fringe exploration strategy i.e. in what manner do we choose the next node to expand. The unifying factor there could be the implementation of these methods. We could just use a priority queue for all of the above approaches. Just the priority would be different in the three cases, deepest first, shallowest first, minimum cumulative cost first being the priorities to be used respectively. (There will however be an implementational overhead if we use a queue in the case of DFS and BFS, where using a stack and a queue would be cheaper space wise.)

Where do searches go wrong?
We need to always keep in mind that the problems we are solving using the above approaches are just models of some real world problems and it is not necessary that there will be compatibility all the time. Any inconsistency with the real world problem could lead to incorrect results from the algorithm. Ultimately, the search will only be as good as the modeling of the problem.

Search Heuristics:
We came to the understanding that even though UCS gives us the optimal path, it does a lot of wasteful computation since it has no information or guidance as to in what direction should it go on checking first. To this extent, we use search heuristics to give the algorithm an idea or guidance as to where should it look for the goal. 
Formally, a heuristic is a function that estimates how close a state is to a goal. Note that a heuristic is a problem specific function and cannot be generalized in nature.

Once we have the heuristic function defined for a problem we can look into two algorithms that utilize it and improve performance   Greedy and A*.

Greedy Search   This algorithm works on the principle of expanding the node that seems closest to the goal state at any instant (as it comes to know with the help of the heuristic).
What could go wrong here? 
We could end up choosing a path that looks good at the moment but ultimately leads us to a non optimal solution. The reason this might happen is that we are not taking into consideration the cost that has already been incurred, and are simply looking at the heuristic to decide the next step. 
In the worst case, this algorithm might work like a DFS that is guided away from the goal. In a way, it would explore all other paths, coming to the goal in the end.

Uniform Cost Search vs Greedy Search:
UCS is slow in the sense that it tries ALL the paths that cost less than the optimal one before coming to a conclusion. Greedy on the other hand works faster as it is guided at every instant to go towards the goal, but it might not work that well as it doesnt take into account the cost already encountered. Now, we could get the best of both by combining ideas from the two.

A* search   expands according to the minimum value of the sum of cumulative cost so far and the heuristic value at the node. In this way, it takes into account the forward (distance from the goal) as well as backward (cumulative cost incurred so far) costs in choosing the next node to be expanded from the fringe. Note that the point of termination of the algorithm is NOT when we enqueue the goal state but when it comes to dequeuing (expanding) a state and it turns out to be a goal state.
Optimality   In general, it does not give an optimal solution if the heuristic is poorly chosen. This means that the heuristic does not estimate the distance from the goal correctly, say it overestimates the distance from the goal. This is called pessimistic behavior of the heuristic.

Admissible Heuristics:
Those heuristics that slow down the bad plans but never outweigh true costs. Pessimistic or inadmissible heuristics on the other hand cause good plans to stay on the fringe for too long and lose optimality in the process.
Formally, 
A heuristic h is admissible (optimistic) if for every node the heuristic value <= the exact cheapest way to get to the goal from that node.

Optimality of A*: If the heuristic is admissible,  A* search would be optimal. 
This can be proved by considering two nodes A and B on a search tree. Say A is an optimal goal node whereas B is a suboptimal goal node. At any point of time, say B is on the fringe along with some ancestor of A (or A itself). This is the case because if B werent on the fringe, we wouldnt have anything to worry about anyway. Also, it isnt possible that none of As ancestors (or A itself) is on the fringe. This is because it would mean that it has already been processed and again we wouldnt be in this situation. Now, B will be blocked on the fringe until A is expanded which proves that A* search will always yield an optimal solution in case of an admissible heuristic. The above claim of B being blocked till A is cleared can be verified by simply using the condition of admissible heuristic which needs to be optimistic in estimating the distance from the goal and the fact that at a goal, the heuristic value is zero.

E.g. 8 Puzzle: A problem which involves a 3x3 board with tiles numbered from 1 to 8 placed in it, leaving one empty state. The goal state is arranging the tiles in some fashion, say increasing order from left to right and top to bottom. An admissible heuristic in this case could be the number of tiles that are not in the correct place. This heuristic is admissible because if a tile is not in the position it is supposed to be, it has to be moved at least once.


References: Class discussion of CS323   Artificial Intelligence.
The slides & video lectures of UC Berkeley CS188.
Russel & Norvig : A modern approach to AI (3rd Edition).
I have not taken any help from any other sources. The above notes are based on my understanding of the content.