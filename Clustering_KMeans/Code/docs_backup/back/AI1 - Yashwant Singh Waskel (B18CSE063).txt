                                                                     Artificial Intelligence (CS343)
                                                                           (1 sep - 11 sep)

# What is artificial intelligence?
->  Artificial intelligence is developing the computer system in such a way that they can be able to do work or task that require human intelligence.
    The tasks can be speech recognition(identify words in spoken language and convert it to machine readable format), translating languages, decision-making, etc..

# What can AI do?
->  Lets take some examples in today’s world which become possible through AI:-
    1)	Read :- News articles, books and more, SummarizeBot can automatically summarize text using AI and machine learning and it also report back the most essential information.
    2)	Decision making :–  AI involves many kind of automation such as scheduling, route planning, diagnosis, web search, fraud detection and many more.
                            AI can also speak. 
                            As we know about Siri and Alexa can respond to queries, Google Duplex uses AI to schedule appointments and complete tasks in a conversational manner.
    3)	Game :– AI has also been taught how to play computer games like poker and chess and decent game of table tennis and jeopardy. 
                A classic moment on May 1997,  the chess match Deep Blue(say machine) vs Kosarov(Chess World Champion), it was the day when first match was won against world champion.
                200 million board positions per second.
                Human were able to understand 99.9% of Deep Blue’s moves. 
    4)	Vision(Perception) :– AI can recognize object and face, it can do scene segmentation(splitting a scene into various object components), it can also classify images.
    5)	It can put away the dishes and fold laundry.
    6)	With the use of AI machines can drive safely along a curving mountain road.

# SCI-FI AI
-> In movies robots can talk, walk, and understand emotions. Some of the sci-fi movies are
   Wall-E, The Matrix and Terminator 2.

# Rational Decisions
-> The term rational defines when someone make decisions in order to maximally achieve pre-defined goals or to maximize the utility(Goals are expressed in terms of utility of outcomes)
   Rationality is not the thought process behind decisions, it concerns what decisions are made.

# Designing Rational Agents
-> - An agent is an entity that interpret the environment and then acts accordingly.
   - A rational agent could be anything which makes decisions, as a person, firm, machine, or software.
   - A rational agent takes actions that can maximize its utility. 
   - An AI system is composed of an agent and its environment. An agent is anything that can be viewed as perceiving its environment through sensors and acting in that environment
     through actuators.
   - Characteristics of environment and action space decide techniques for selecting rational actions.
   - A famous game Pac-man in which Pac-man works as an agent, it precepts the environment and then take actions accordingly.

# Agents that Plan
-> 1) Reflex Agents
      - Reflex agents are the agents that ignore the rest of percept history and take action based on current percept.
      - They may or may not have memory i.e., ability to store the past actions or results.
      - It does not consider the future consequences of their actions.
      - Reflex agents which operates in partially observable environments, infinite loops are often unavoidable. 
        It may be possible to escape from infinite loops if the agent can randomize its actions.
      - To change behaviour of reflex agents we have to rewrite many condition and action rules.

   Q) Can a reflex agent be rational?
      A reflex can be rational if it takes the correct decision at every step to reach its goal.

   2) Planning Agents 
      - These agent should have a goal. 
      - They take decisions based on consequences of the actions and for that they should be aware of the world’s environment.
      - It take decisions based on how far is it from the goal, their action is intended to reduce its distance from the goal. 
      - Search and planning are the subfields of AI, require to find action sequences that achieve the agents goals. 
      - The planning agent’s behavior can easily be changed to go to different destination by specifying destination as a goal.
                    
    $ Optimal planning vs Complete planning
    - Optimal planning is a planning which takes us to the goal in least time complexity or we can say the best possible way whereas complete planning also takes
      us to the goal but its time complexity may not be least. Optimal planning is always a complete planning but not vice-versa.

# Search Problems
-> - To achieve the desired task the agents perform some kind of search algorithm in the background.
   - A search problem consists of :-
     o	State space :- It the set of all possible states which can be reached from initial state through any possible sequence of actions.
     o	Successor :- It refers to any state reachable form a given state by a single action.
     o	Successor function :- It returns set of all successors, instead of separate actions and costs.
     o	Start state :- The state from where the agent starts search.
     o	Goal Test :- It is the set of all goal nodes(may be one). It determines whether a given state is a goal state or not. For example, in the game of chess, the agent’s goal is to 
                     check mate i.e., opponent’s king is under attack and can’t escape, in the game pac-man the agent’s goal is to eat all the dots without getting caught by the ghosts.

   - A solution for a search problem is the sequence of actions (called plan), that takes agent from the start state to goal state.
   - For example :- Travelling in Romania
                    The graph of the cities in Romania is {(city1)(distance) <----> (City2)}
                    {(Arad)(75) <----> (Zerind)(71) <----> (Oradea)(151) <----> (Sibiu)(140) <----> (Bucharest)},
                    {(Arad)(141) <----> (Sibiu)}, {(Arad)(52) <----> (Dobereata)(88) <----> (Sibiu)}
                    Arad – Initial state, Bucharest – Final state

                    Therefore, the State space – cities;
                    Successor function – Roads (Cost = Distance);
                    Start state – Arad;
                    Goal test – Is state == Bucharest?;

# What’s in a state space?
-> - Every search problem depends on what we are trying to do. It is always defined in the context of the world or environment.
   - Lets take the game of Pacman, this problem can be divided into two, first is to find the path and second is to eat all dots. First lets look at the pathing problem,
   - In this, the states can be defined by the (x,y) coordinates.
   - The actions can be the set of possible states we can move from current state.
   - Successor function get update of the location.
   - Goal test is the (x,y) coordinates where we want to reach.

   - Eat-all dots problem:-
     - In this, the states are the (x,y) coordinates containing dots.
     - Actions are the set of all possible states we can move from current state.
     - Successor function get updates of the location possibly which contain dots.
     - Goal test would be to eat all the dots.
 
   - A search state keeps the details essential for planning.
   - The world state is consists of all possible details of the environment.

# State space graphs
-> - If we consider each state and possible paths from one state to another we get a graph. 
   - For every search problem there is a state space graph.
   - A state space is a set of all nodes(world configurations) representing each state of the problem.
   - Arcs are the valid moves or actions from one state to another(Successor function).
   - Each state space takes the form of a tree or a graph.
   - It is very difficult to build the full graph in memory because it’s too big.

# Search tree
-> - In this, the start state is the root node. 
   - From each node its neighbours are the child nodes which are directly connected or we can say, children correspond to successor. 
   - It is possible to reach to same state or node from different child nodes.
   - Different plans that achieve the same state, will be different nodes in the tree.
   - For most of the problems it is not possible to build the whole tree.
   - Because of restriction in memory, we cannot explore too much deep in the tree.

# State space graph vs Search tree
-> - In state space graph, we consider all states and the transition between them.
   - In search tree, we consider path between two particular states. More than one path can be possible for two states.
   - If there is a cycle in the state space graph then it is possible that the search tree may be infinite.
   - For example,
               Consider the graph, (City 1) --> (City 2)
                              (a)-->(b) || (b) --> (a)  || (c) --> (a)  || (c) --> (b)  ||  (a) --> (d)  || (b) --> (d) 

               For the above graph, the search tree size will be infinite because of loop in the graph.

# Searching with a search tree
-> - First we build a tree with start state as root node. Then child will be the state to which we can go from current state to another state if there is an edge between them and these
     process will be continue till all possible nodes are puted in the tree, it is also possible that the tree can be infinite if there is a cycle.
   - First we expand the start node i.e., it's child node and then expand child node. Now, we can go to any child node and that will depend on the algorithm we choose, may be DFS or BFS or
     some other algorithm.
   - Also, we maintain a FRINGE which we store the nodes yet to be expanded in the given context. The nodes in the fringe can be the nodes which are visited but not expanded.
   - Suppose that we have created two queues, one is a fringe and the 2nd queue. Now, suppose we start from root node, then that node will be in the fringe, now we take this node out of the
     fringe and expand it and push its children in the fringe for further expansion. The node which is explored push it in the 2nd queue. We will also take care of the visited nodes and we 
     will not push it in the fringe.
   - Pseudo code for performing tree search :- 
                                       ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
                                       ||      function Tree-Search(problem, starategy)    returns    a solution, or failure           ||
                                       ||               initialize the search tree using the initial state of problem                  ||
                                       ||               loop do                                                                        ||
                                       ||                   if there are no candidates for expansion    then return    failure         ||
                                       ||                   choose a lead node for expansion according to the strategy                 ||
                                       ||                   if the node contains a goal state then return the corresponding solution   ||
                                       ||                   else expand the node and add the resulting nodes to the search tree        ||
                                       ||               end                                                                            ||
                                       ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
                      The strategy is how we are exploring the nodes, it could be DFS or BFS.
                      Choosing the leaf node from the fringe for expansion as per the strategy.
                 
                Some important ideas:-
                - Fringe :- It will contain the nodes yet to be explored.
                - Keep track of the nodes which are already visited.
                - Exploration strategy :- The technique in which the nodes are expanded.

                It is important to choose the best technique to select the fringe nodes to expand because it will make impact on the search mean less computation is possible.


# Uninformed Search
-> These strategies do not have any additional information about the goal other than the information given in the problem.
   Some of the strategies are:-
   - Depth first search
   - Breadth first search
   - Uniform cost search

# Depth First Search(BFS)
-> It is the search method in which we expand the deepest node from the current node.
   Strategy :- The strategy which we will use is expanding the deepest node first.
   Fringe :- The fringe which is used is stack(i.e., LIFO method)

   We start from expanding the first node and further expand till we get the goal node or the leaf node. If we get the leaf node then we will traverse back to leaf nodes parent node,
   if the parent node has more child yet to be explored then we will explore that in deep and search for our goal. Also we may have to make another fringe to take care of the node
   appearing in current path first time but has already expanded, in this case we have to expand it again if it is coming first time in that path.
   With the help of DFS we will get a complete solution but we cannot say that it is an optimal solution. 

   - Properties :-
     - DFS can expand some left prefix of the tree. It is also possible that we have to explore the whole tree which will be the worst case.
     - Therefore, the worst case time complexity will be O(b to the power m), where 'b' is number of child nodes of a node and 'm' is the height of the tree considering root node at height 0.

     What will be the space complexity?
     - The space fringe does take is O(bm) i.e., we have to take care of siblings.
       Because we have to keep track of all the nodes in each level, we will clear the fringe after each level.

     Is it complete?
     - Yes, it is a complete solution if we take care of cycles in the graph.

     Is it optimal?
     - No, it is not an optimal solution because it will always go to leftmost node first without taking care of depth or cost. 

# Breadth First Search(BFS)
-> This is the search method in which we explore across the breadth of the tree.
   Fringe :- The fringe used is queue(FIFO).
   
   Time complexity :- O(b to the power m), where 'b' is the number of child nodes of a node and 'm' is the height of the tree considering root node at height 0.
                      The worst case would be if the goal node is in the righmost part of the tree then we have to explore all the nodes of the tree.
 
   Space complexity :- O(b to the power s) because at level s we have expanded b to the power s nodes.
   Complete solution :- It is a complete solution. If there is a solution then s must be finite.
   Optimal solution :- It will be a optimum solution. If the cost(cost of moving form one node to next node) is one.

# When BFS outperform DFS?
-> BFS outperform DFS when we have to find the shortest path form one node to another.

# When DFS outperform BFS?
-> DFS outperform BFS when we have to see all possibilities, and check which one is the best possible ways.

# The advantage of DFS over BFS is its space complexity.

# Uniform Cost Search(UCS)
-> When all step cost equal, BFS is optimal because it always expand the shallowest node which is not expanded. The algorithm which is optimal with any step cost function is UCS algorithm.
   Strategy :- UCS first expands the node with cheapest cost.
   Fringe :- The fringe which is used in UCS is priority queue ordered by cumulative cost.
  
   Properties :-
   - UCS expand the nodes with cost less than the cheapest solution.
   - If the cost of that solution is C and arcs cost at least E, then the effective depth is roughly C/E.
   - Then the time complexity = O(b to the power (C/E))

   - Space taken by the fringe is roughly O(b to the power (C/E)).
   - Yes, it is a complete solution assuming best solution has finite cost and minimum arc cost is positive.
   - It is an optimal solution.

   Advantage:- It is complete and optimal.
   Disadvantage :- - Explores all possible nodes in every “direction”.
                   - No information on goal location.

# The one Queue
-> All these uninformed search algorithms are the same except for strategies for the fringe.
   Conceptually, all fringes are priority queues (i.e. collections of nodes with attached priorities)
   For DFS which is LIFO we choose the fringe corresponding to least time stamp value and for BFS which is FIFO we choose fringe corresponding to maximum time stamp value.

# Search gone wrong
->  Some it is possible that the model information is not appropriate which is not the fault of agent or search algorithm.
 
# Pancake Problem
-> It is kind of a search problem.
   Suppose we have given some pancakes with different sizes. We have to arrange this pancakes in increasing order form top. The constraint for sorting is that we can only flip a subset of 
   pancakes starting from top always i.e., from top select a depth and flip that pancakes from top to depth. We can flip only top few pancakes, the last one may be included.
   
   We can consider it as a search problem. It's state space graph will includes pancakes with all possibility of flipping from current state and the cost of moving from one state to another
   is the height of pancakes selected from top.
   
   For example, consider array a={4,1,2,3}, a is the root node of the tree. Cost is written in (cost).
                               
                                                {4,1,2,3} 
                                            (2)/   |    \
                                              /    |(3)   \(4) 
                                     {1,4,2,3}  {2,1,4,3}  {3,2,1,4}
                                    /      \                 /      \
                                (3)/        \(4)         (2)/        \(3)
                          {2,4,1,3}       {3,2,4,1}    {2,3,1,4}      {1,2,3,4}   <-------- Goal (cost=7)

                  We will follow the General Tree Search algorithm(stated before) with a specific fringe technique.

# Informed Search
->  The agent has additional information about the goal state other than the definition of the problem.
    In informed search we will make use of a Heuristic function.

# Search Heuristics
-> A heuristic is a function which estimates how close the current state is from the goal.
   It is designed for a particular search problem.
   Examples of heuristic for pathing are Euclidean distance(it is displacement between current state and goal state), Manhattan distance(suppose consider a right angled triangle with 
   vertices of hypotenuse as goal state and current state, then the sum of other two sides is the Manhattan distace and hypotenuse is Euclidean distance).

# Greedy Search
-> It is the algorithm which takes best path from the current state. The disadvantage of this algorithm is that we may not the optimal solution in the long run.
   strategy - Expand the node that seems to be closest to the goal state
   Use heuristic to estimate the distance to nearest goal from each state
   It may happen that in most of the cases we may not get an optimal solution.

# A* Search
-> As we know that UCS is a slow process but it provides us the optimal solution and greedy approach is fast but it is not optimal. Therefore, if we combine both UCS and greedy we may reach
   to a better solution.

   - Combining UCS and Greedy

     Consider a graph,  
                      vertices - {s,a,e,b,c,d,g}
                      h = heuristic value (distance from goal state)
                      On edges cost is given
                         
                                                     h=3
                                                     (e)-------1-------
                                                      ^               |
                                                      |8              |
                                                      |               V
                                         h=6(s)--1-->(a)------3----->(d)----2---->(g)h=0
                                                      |h=5           h=2
                                                     1|
                                                      V
                                        h=7 (c)<--1--(b)
                                                      h=6
                                          In greedy approach we are relying on heuristic value, or forward cost h(n).
         In UCS, we consider the cost each path, for example, cost of reaching d from s through path s->a->d is 4, and through path s->a->e->d is 10.
         These cost is backward cost g(n).

         In A* search, the sum of backward and forward cost is calculated, i.e., f(n) = g(n) + h(n)
         These value is used in getting the priority of the path.

# When should A* terminate?
-> We should terminate the process of A* after taking out the goal state from the fringe i.e., dequeuing the goal state. 

# Admissible and Inadmissible heuristics
-> Admissible heuristic is the heuristic that underestimates the true forward cost. They slow down the bad plans but never outweigh the true costs. They are pessimistic(believing that 
   worst will happen).
   Inadmissible heuristic is the heuristic that overestimates the true forward cost. It breaks the optimality by trapping good plans in the fringe. They are optimistic.

   A heuristic h is admissible if 
                               0<= h(n) <=h*(n), h*(n) is the actual shortest path or say, true cost to the nearest goal.
   If there are multiple paths then h(n) should be in this range.

   Manhattan distance is admissible heuristic.

# Optimality of A* search
-> Let's assume that
                    - A is the optimal goal node
                    - B is the suboptimal goal node(it is the goal node whose cost is more than that of A)
                    - heuristic h is admissible

   Prove that A will be out of the fringe before B
   Proof :-
           - Suppose that B is in the fringe
           - Some of  the ancestors of A is also in the fringe, it may be root node or A itself.
 
           - As we know that
                            - f(n) = g(n) + h(n),
                              and f(n) <= g(A), because h is admissible in this case.
                              also, g(A) = f(A), because heuristic h=0 at the goal node.

                              Because of above relations, it is concluded that {f(n) is less than or equal to f(A)}.
                            
                            - As B is suboptimal, therefore, g(A) < g(B), because cost of B is greater than A.
                              also, f(A) < f(B), because h=0 at the goal node.
                              From above we can conclude that {f(A) is less than B}.

                            - from above two conclusions, we can conclude that {n will expand before B, as f(n) <= f(A) < f(B)}
   
           - This implies that all the ancestors of A expands before B.
           - Thus, A will be out of the fringe before B.

           Hence, A* search is optimal.

# Properties of A* search
-> In UCS we only make use of cumulative backward cost whereas in A* we use cumulative backward cost and heuristic value too.
   Also,in A* search more computation is required with respect to each node.
   UCS expands equally in all the directions while A* expands nodes which are towards the goal node which makes it optimal.  

# Applications os A*
-> Language analysis :- Suppose take the example of wikipedia corpus, we can make graph starting from a word and link it according to possible words next to it. Then if we search some 
                        starting words then we can get the whole sentence.Therefore, it is a kind of search problem.
   
   Machine analysis :- Suppose we have translate an article in two different languages then by relating words and searching their connectivity we can convert the sentence into two different
                       languages.

   Speech recognition

# Creating Admissible heuristic
-> With admissible heuristic we get the optimal solution but the computations are large. If we want to solution in less computation then inadmissible heuristic is good but we have to 
   compromise with optimality.
   Also, admissible heuristics are solution to relaxed problems. Relaxed problem means that the agent has more actions. For example, to travel from one city to another we have constraint
   that we have to follow the path and if we can fly direclty from one city to another. In this case we can consider the euclidean distance between two nodes or say cities.

# Example: 8 PUZZLE
-> Consider a 3x3 matrix block with numbers 1 to 8 and one empty block. The goal is to arrange the matrix in such a way that empty block is at (1,1) first block, and from (1,2) second block
   there should be 1, at (1,3) there should be 2, at (2,1) there should be 3 and so on.
   The restrictions to the problem are that we can only shift blocks adjacent to the empty block. If the empty block is at (1,1) we can have only two choices to either shift (1,2) block or
   (2,1) block. If the empty block is at middle of the matrix (2,2) we have four choices (1,2), (2,1), (2,3) and (3,2).
   
   - What are the states?
     States are the possible configuration after each possible shifting with the empty block.

   - How many states?
     Total solvable states = 9!/2 , because there will be total 9! trasitions but 9!/2 transitions are not solvable. For example,
     this configuration is not solvable
                                         1  2  3
                                         4  5  6
                                         8  7

   - What are the actions?
     We can slide any possible digit in empty block.

   - How many successors from the start state?
     No. of successors depends on the position of the empty square. For example, if the empty square is at any of the corner vertices then there will be two successors, if it is at middle
     i.e., (2,2) then there will be 4 successors.

   - Heuristic in 8-puzzle
     No. of tiles misplaced. Heuristic value will be Euclidean or Manhattan distance of each tile from its desired goal.

   - Is it admissible?
     Yes, because in every step we are trying to move the block near to its goal position. 



















 







