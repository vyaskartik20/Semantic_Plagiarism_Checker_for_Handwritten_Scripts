Name: Chintala Nirmal Srinivas
Roll No: B18CSE010

A* search is like a trade off between work we done per node  and the quality of estimation. In the case of 8-puzzle where there is a 3x3 matrix ie with number 1 to 8 and one empty space in it.The probem i to arraange them such that they are in the cending order. Consider a heuristic which always gives the value zero. This is admissible as this is equal to  UCS and it expands many nodes as steps increases. Consider a heursitic which calculates the nodes which are misplaced. This is also admissible as up to some extent, we are able to relax the problem.In this case, computation increases slightly and expansiosn decreases.Consider a heuristic which computes manhatten distance for evry distance and sums them. This is also admissible as we relaxed the problem.In this case we get a better idea as we approaching the goal. This approach is better than the 2nd approach but computation increases. So we can conclude that A* search acts as trade off between work done per node and quality of estimation.

Graph Search: In tree search, we visit some nodes repeatedly. In graph search, we can avoid this repeated visiting of nodes. To perform this task, we keep track of the states we already visited. 
So we use a set called "closed set" to keep track of expanded states. 
Initially we will be given a start state and we push it into the fringe. We pop out a node based on our priority and expand it and push it into the closed set. So whenever we want to expand a node, we will check whether the node is already expanded or not by searching from the closed set. A closed set is a set but not a lost because searching can be done quizkly in a set. We get a complete solution using graph search but may get a sub optimal solution using A* graph search. When we use uniform cost search on graph , we get a optimal solution. Incase of admissibility, heuristic cost from start state to goal state should be less than or equal to actual cost to goal. Consistency of heuristics: heuristic arc cost should be less than or equal to actual cost for each arc. Consider there is an arc with states A,B then h(A)-h(B) <= cost(A to B). We need consistency of heuristics incase of graph search to get optimal solution.So we can say that f value will not decrease along a path. Optimality of A* graph search: Consider there are two goal states, so there are two different paths to reach the goal. f value will increases as we are approaching our goal. We will take out that goal state whose path has less f value, so that impllies we will get always optimal solution with A* graph search given that the heuristic function is consistent. In the case of tree search, A* will give optimal solution if the heuristic function is admissible. Note that Consistency implies admissibility.

Constraint Satisfaction Problems: There are different types of tasks based on which different search methods are used. One is planning task, in this case the path to reach the goal is important.Other type of tasks are identification tasks in which goal is important but not the path. We are looking for a goal and it is an assignment to a set of variables. CSP falls under identification type of tasks.In CSP, a set of variables will be given which is the state in CSP and the values are assigned to these variables from domains which may vary for each variable. Values are assigned to these variables such that given set of constraints must be satisfied. Example is map colouring in which the constraint is neighbour states should not have different colors and the number of colours which can be used depends on the domain. Another example is N-queen problem in which N queens must be placed on NxN board such that any two queens cannot attack each other. Contraint graphs: In constrant graphs, an edge denotes that there is a constrant between those two states. If eaach constraint denotes relating atmost two variables, then it is binary CSP. For a cryptarithmetic problem, variablles will be the letters and carry and domain is the set containing numbers starting from 0 to 9. We use auxilary nodes in constraint graphs denoting multiple variables in constraints. Waltz algorithm: Waltz algorithm is used in interpreting the geomtric object. It produces a line diagram based on an image and it denotes the geometry of the image. In this case we take each intersectionas variable and adjacent intersections will impose constraints on each other.Varities of CSPs based on different type of variables: One type is based on discrete variables in which domains can be finite or infinite. Second type is continuous variables. Varieties of constriants: unary constraint which involves a single variable, binary constraints which involve pair of variables and higher order constraints involving three or more variables. The goal test in CSP will be assignment must be complete and it must satisfy the constraints. Search methods: In BFS, our start state will be the state containing unassigned variables and when we go down we assign some colour to unassigned variable. In each level some colour is assined to all the unassigned variables.In DFS, colours is assigned only to one unassigned variable. Uninformed search methods like dfs or bfs do a lot of search so we need to come up with better search method. One more isuue is whenever some constraint is violated, the search method won't stop and continue assigning the colours. 

Backtracking search: Backtracking search is a search method which is made after some modifications are made to DFS based on continuing the search eventhough constraints are not followed. In backtracking search, we need toconside assignments to a single variable in each step and constraints check must be done after each assignment.In the algorithm,  in the first step we select an unassined variable and a colour is assigned to it from domain and similarly colours are assigned to the unassined variable for the remaining neighbour of same parent with different colours on the order they present in the domain. Now, we will expand the first child and assign colours to unassigned variables and if the constraints are violated, then we stop assigning the colours and we backtrack and select another state. Filtering: omitting the possbilities which violate the constraints before assigning the colours. So, we keep track of those unassigned variables and we remove those cases which violate the constraints. Incase of filtering,we will backtrack when some variable has no colour to get assigned from the domain of colours eventhough constraints are not violated. Consistency of single arc: An arc x -> y will be consistent if and only if for every x there is one y to which some colour is assigned without any constraint violation. If there is any violation we remove the colour from tail node(x) which violates the constraints. If some colour is removed from the tail, neigbours of the tail needs to be checked again.This is a disadvantage. Runtime is O((n^3)*(d^3)). n is the number of variables and d is the domain length. we need to check the nxn arcs => n^2 and in worst case we need to check all the possible colours dxd => d^2. If there is any violation we need to check again => (n^3)*(d^3).There are some limitations in arc consistency. After enforcing the arc consistency, we can have one solution or multiple solutions or no solutions left since we assign only using pair of two variables. Ordering of variables: (Minimum remaining values) Select that variable which has the least legal left values.Least Constraining Value: Choose the variable such that domain of neighnours gets least affected. But it takes time for computations.

Local Search and Optimization: Incase of local search, the agent make a move after looking at its neighbours.Incase of local search, agent need not simulate all the different plans as other agents do. So there is less memory requirement for the agents used for local search. So the advantage is solution can be searched eventhough the search space is large. Algorithms used for local search are Random Sampling(select some state randomly which correspond to some solution) and Random Walk(randomly pick some neighbour node).Consider a problem hill-climbing which return a state that is local maximum. Here maximum refers to the maximum value of objective function. We start with a state and from this state we check for neighbour states which have higher value, we walk to that state or we stay in that state. Finally we return the local maximum value. These values correspond to objective function or heuristic function. We find the higher value in the neighbouring states correspond to the current state.The local maximum(end state) depends on our start state. Consider n-queens problem, if we want pose the problem as constraint optimization problem(minimize the number of attacks), the objective function will be the number of pairs which are attacking each other. The aim is to minimize this number. In this problem, state space represents some configuration and successor function represents the moving of one queen to another square in same column and h(n) represents the number of pairs of queens attacking each other. 

When we use local search, the h will be the local minimum but it may not be zero. Drawbacks in the case of hill climbing: end state depends on start state, local maximum can be the minimum value and diagonal ridges.Sideways moves helps us to move from problems like plateaus. It raises the percentage of problem instances solved. Through sideways we remember some neighbouring states including the current state. This search is tabu search. We maintain a queue in which we add the states we visited into it. Inorder to avoid problems like local maximum, we add randomness in our approach. They are random-walk(randomly walking into one of the neighbouring states), random-restart(randomly selecting one of the states and search for higher value in it's surroundings).

Escaping shoulders/local optima enforced hill climbing: It means whenever we encounter a plateaus, we use bfs to find out the state with better h function. It is like a middle ground between local and systematic search.Simulated Annealing: Simulated Annealing is another kind of local search algorithms. The idea of this algorithm comes from the process of heating. When we heat the metal, particles gain some energy and excite and when the temparature goes down, the particles reaches a stable state losing their randomness. It is similar to hill-climbing but some modifications are there. We don't always take the best move. With some probability, we are also allowed to walk to neighbouring states.Local beam search: The idea is to keep track of k states instead of one state. We first select k selected states randomly, and determine the successors of those k states. When we reach the goal, we stop the search or select the best k from the successors and repeat the process. This selection of k random states run in parallel.

Limitations of local beam search: It does not ensure diversity eventhough we are selecting k selected states(they may end up on same local maximum). So to oversome that, we select k random states instead of selected states.This search methiod is called Stochastic beam search. Genetic Algorithms: Assume a pair of states called as parent states. From these we get successors and some fitness function is assigned to each state. Fitness functions describe the chances of surviving(how fit the state is). Genetic algorithm is variant of stochastic beam search.The advantage of genetic algorithm is finding solutions through random exploration which local search can't find.The disadvantage is uncertainity i.e, for example we select k random states in the beginning which is a point of uncertainity. Similarly, there is randomness involved in the approach because of which results may not be the same.Optimization of continuous functions: Consider the case of hilll climbing, this is meant for discrete tasks. Large number of algorithms also based on the idea of hill climbing. This leads to the notion of Gradient discent. In gradient descent also, we move down or up the hill but in a continuous space. Assume we have a function which is continuous f(x1,x2,..xn) and the aim is to minimize over continuous variables X1,X2,..Xn. So we first compute the gradients for all and take a small step in the direction of gradient down the hill and repeat the process.




 
