						Lecture Notes:1(01/09/2020-11/09/2020)

Artificial intelligence has become one of the most important fields of computer science nowadays. With the increase in data volumes,advanced algorithms and advancement in computing power and storage, Artificial Intelligence has become more popular today.While Hollywood movies and science fiction novels depict AI as human-like robots that take over the world, the current evolution of AI technologies isn’t that scary – or quite that smart. Instead, AI has evolved to provide many specific benefits in every industry.

The objective of artificial intelligence is to make machines that can act like humans, think like humans or may be better than humans in some aspects.Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The ideal characteristics of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. Being rational here is in the context of achieving a goal. Being rational means maximally achieving the predefined goals or to maximise the expected utility. Artificial intelligence  is used in various fields like natural language generation,speech recognition,robotics,Natural Language Processing,etc.  

When we talk about Artificial intelligence we generally say agents.Any entity that perceives and acts in an agent. An agent can be a robot, a machine,or any artificially intelligent entity. There are two types of agents: Reflex agents and planning agents. Reflex agents take actions based on the current state or may use information from older states to take further action. There are two types of Reflex Agents. First is Simple Reflex agents, which take actions solely based on the current percept and they are unable to use information from the older states, i.e these types of agents do not remember any information from the past. Second one is Model Based Reflex Agents. These types of agents keep track of previous actions taken(we can say that they have memory, which they update after every action they take). The current percept is combined with the old internal state to generate the updated description of The current state.Reflex agents may not always be rational. Rationality of the Reflex agents depends on the environment as well as the action they take at each step.

The second one is planning agents. Before these agents take an action they do some sort of planning and try to analyse the consequences of their actions. To do so they need to be aware of the environment in which they are acting and also need to be aware of the goal. They explore the environment before they make any action. In case the environment is huge then they may not explore the entire environment. They may explore the environment with some restrictions. 

When we talk about planning, there are two types of them. First is complete planning and the second is optimal planning. Any Plan that will lead us to our goal is a complete plan. The optimal Planning is the one that leads us to our goal in the best possible manner i.e in most effective and efficient manner. For example,say we have to go from city A to city B. There are two plans to reach city A for city B. One is directly from A to B(which is a shorter route) and the other is from A to C, then C to B(which is a longer route). Assuming that other factors like traffic,cost,etc are the same for both the routes, both the plans are complete but only the first one is optimal as it takes us to our goal via the shortest path. An optimal planning will always be the complete planning.

One of the important algorithms that we need in AI is searching algorithms. Searching has a lot of use in AI. Thus we need to come up with an optimal searching algorithm. A search problem consists of a start state,a description of possible actions available to the agent(state space),description of the action(i.e what it does), cost of the action and a goal test.The way we define our state space depends on our problem. To understand it better we can consider a connected graph of cities with start state as S and goal state/test as D. Now to search an optimal path from initial state to goal state we need to know what are the cities that we can reach from the current city(cities adjacent to the current city) and what is the cost of doing so. Everything needs to be given as input in order to come up with a solution. A solution to a problem is a sequence of actions that leads us from start state to goal state. The term goal test is used because our goal test may not always correspond to  a state. 

Whenever we talk about a search problem we try to model our environment or we try to approximate our environment so that we can work with it using a machine. For example one simple approximation is if we think of moving from one point to another, then we approximate that the space between two points can be discretized. We can think of our state space as a graph or tree. First let us consider the state space graph. Nodes in the graph represents the world configuration and the directed edges represent the result of actions taken(successors). The goal test is a set of goal nodes which may be a single node or multiple nodes.Each state in the state space graph appears exactly once. It is practically not possible to store the entire state space graph as it would require a lot of memory space. For small problems it can be possible to store entire state space but as our environment for the problem becomes bigger we won’t be able to store the entire state space.

Another way of storing the world state information could be a search tree. It may not contain all the possible states but it contains several possible paths or plans. A search tree starts from a root node and as we move one level down we will get the next possible states. A search tree can have repetition of states because it may be possible that we can reach a particular node via two or more paths. So the search tree would contain all the paths leading to repetition of states.If a state space graph contains a cycle then the search tree would be infinite as it would lead to a lot of repeated structure in the tree.Therefore, we put some additional constraints or conditions in our algorithm so that we may not end up in a loop.However, it is not possible to build a search tree for all the problems. Also we may not explore the whole search tree in practice. We consider a given state and look for the various possibilities where we can move. Since there is limitation in terms of computational resources, we may restrict the depth upto which we explore the search tree.

The generalised search algorithm would look like:

Function Search(problem,strategy): This function would return the solution or failure if it couldn’t find any solution. Start from the initial state and do the following
Loop
If there are nodes in the fringe that are to be expanded return failure.
Else choose a node according to the strategy.
If the chosen node is the goal state, return the solution.
Else expand the node and add the resulting nodes to the search tree.
End

Depending on how we maintain the fringe, there are various algorithms for searching. First is Depth First Search. DFS starts from the start node and it would always pick the deeper branch until it reaches the solution or it runs out of nodes and backtracks. In DFS the fringe is a stack that follows the Last In First Out(LIFO) strategy. DFS will always provide us a solution(if it exists). If we can handle the cycles, DFS will give us a complete solution but it does not guarantee an optimal solution.DFS will always find the leftmost solution regardless of cost or length of the solution. If b is the branching factor and m is the maximum depth of the search tree then the total nodes in the search tree would be b^m. The time complexity of DFS would be O(b^m) because in the worst case we would have to explore all the nodes of the search tree. The space complexity would be O(bm) because at each level we will have to keep track of b nodes and there are total m levels.

Another search algorithm is Breadth First Search(BFS). BFS starts from the root node and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level. In BFS the fringe is a queue which is based on a First In First Out(FIFO) strategy. BFS will always provide us the solution if there exists one. If the number of levels in the search tree is finite, then the BFS would always give a complete solution. However, it will provide an optimal solution only if the costs are all 1.If the goal node occurs at level s, and the branching factor of each node is b, then the time complexity of the solution would be O(b^s) because we would have to explore each node till we reach the goal state. The space complexity would also be O(b^s) because we will have to keep track of all the nodes at level s in order to expand them in the next level.

BFS finds the shortest path in terms of the number of actions but it does not find the least-cost path. An algorithm similar to BFS that finds the least cost path is Uniform Cost Search. Our goal is to find the path which has the least cost.At each step we expand the node which has the least cumulative cost. The fringe in this case will be a priority queue where the priority is the cumulative cost. The top of the priority queue will contain the plan with the least cumulative cost. Every time we take the plan with least cumulative cost from the fringe and expand it. If the node taken out is the destination node, then we return  that plan as our solution to the problem else, we keep on exploriing the plans. If we couldn’t find the goal node and the fringe is empty then we return failure,i.e were not able to find the solution. If the cost of solution is C and the arc costs at least 𝞊, then the effective depth would be C/𝞊. If b is the branching factor, then the time complexity of Uniform Cost Search will be O(b^(C/𝞊)). The space complexity will O(b^(C/𝞊)) because the fringe has roughly the last tier. If all the costs are finite, non-negative and arc cost if positive, then Uniform Cost Search will give us a complete as well as Optimal solution. If the costs are negative then the algorithm may not give the optimal solution. Although it will give us the complete solution, it may not give us the complete solution because in the case of negative cost we will have to explore all the possible plans to the destination node then only we can choose the optimal solution. If we stop after finding the first possible solution then it is not guaranteed that this will be an optimal solution as there can be other paths with cost less than that we found. The Uniform Cost Search has drawbacks that it has to explore options in every direction and it does not have any information about the location of the goal.

The algorithms that have been discussed till now are called Uninformed Search algorithms. These types for searching techniques have no additional information about the distance from the current state to the goal. Thus the algorithm has to explore in all the possible directions to find the optimal solution. Thus a lot of work is done in vain in these algorithms as the solution exists in only one direction but we have to explore all.

There is another type of searching technique known as informed search. This technique has the additional information about the estimated distance from current state to the goal. Such algorithms use heuristic functions to get the estimates . A heuristic is a function that gives the estimate of how close the current node is from the goal. How heuristic function id define depends on the type of problem. Example of heuristic function could be a function that returns Euclidean distance or Manhattan distance between the current node and the goal. For example, in a path finding problem the heuristic function can be defined to return the straight line distance and in the pancake flipping problem the heuristic function can be defined to return the number of largest pancake that is still out of place.

The first type of such algorithm is Greedy Search. In greedy search algorithms the idea is to expand the node that seems closest to the goal according to the heuristic function. For the path finding problem we start from the start node and keep expanding the node with lowest heuristic value from the fringe(assuming that the heuristic function is defined to return the straight line  distance between the current node and the goal) and keep doing so until we reach the goal node. The greedy algorithm will give the complete solution if it exists  but it may not give the optimal solution. In the worst case we may end up doing more work than the uninformed algorithm. This can happen if there are many paths that come close to the goal but does not lead us to the goal. In this case we will be able to find the solution only after exploring all the possible paths, thus we may end up doing more work than uninformed search(like a badly guided DFS). Greedy search may give us the optimal solution sometimes and sometimes it will do more work than DFS and BFS. 

We have seen that Uniform Cost Search gives the optimal solution, however it is slow as compared to Greedy Search. On the other hand Greedy solution is fast but it will not always provide us the optimal solution. So we can make use of both the algorithms to come up with a new algorithm which is better than both the algorithms. The algorithms that make use of both of them is A* search. The Uniform Cost Search orders by the path cost or cumulative cost [g(n)] and the greedy algorithms orders goal proximity or forward cost [h(n)]. In A* search we take summation of both these costs to decide the priority of the plans in the fringe. The plan with the least value of g(n)+h(n) is taken out of the fringe and explored first. Now here the questions is when should the A* search start? Should it be when we enqueue the goal or when we dequeue the goal? Now, if we stop the search when we enqueue the goal then, it is possible that the plan containing the goal may not be the optimal plan, it was enqueued early due to its ancestors. At the time of enqueuing we cannot ensure that the plan that is enqueued first is the optimal one, however while dequeuing a plan we can ensure that. Hence the A* search should stop only when we dequeue the goal. Another question is will the A*  search always gives us the optimal solution? The A*  search will give us a complete solution but it will not give optimal solution always. If the estimated path cost(as estimated by heuristic function) is more than actual cost the A* search will not give the optimal solution.

Thus in order to get the optimal solution we need estimates to be less than actual cost.In order to keep check on heuristic value look at the admissibility of heuristic. Admissible heuristics are those for which the heuristic value is less than the true cost to the nearest goal.Admissible heuristics are optimistic which slow down the bad plans but never outweigh the true cost.Inadmissible heuristic are pessimistic which breaks optimality by trapping good plans on the fringe. Now, in order to prove that A* search is optimal, we consider two nodes, say A and B. A is an optimal goal node and B is a suboptimal goal node and h is an admissible heuristic function. To prove that A* search is optimal we will have to prove that A will come out the fringe before B.In order to prove that, assume that B is on the fringe and some ancestor of A(say n) is also on the fringe.

Now due to admissibility of h, f(n)<=g(A) [Here f(n)=g(n)+h(n)] and also g(A)=f(A) [since h(A)=0]. Therefore, f(n)<=f(A), which means f(n) will be expanded before f(A).Now since g(A)<g(B) (because B is suboptimal) and h(A)=h(B)=0, therefore f(A) is less than f(B).Now since f(n)<=f(A)&&f(A)<=f(B), we can say that n will expand before B. This means that all the ancestors of A expanded before B which implies that A expands before B. Thus we have proved that A* search is optimal.

A* search is expected to give the optimal solution and at the same time it is expected to explore less than the uniform cost search algorithm. In uniform cost search we only use cumulative cost to explore the nodes whereas in A* search we also use heuristic function along with the backward cost. If the heuristic is admissible then A* search is optimal. Uniform Cost Search expands equally in all directions without having information about the goal, whereas the A* search expands in the direction of goal, therefore, A* search explores less than the Uniform Cost Search. A* search may end up searching more than the greedy search, but it will always return the optimal solution if the heuristic function is admissible. A* search has wide application in searching because it is optimal and it explores less than the Uniform Cost Search. A* search can be used in path/routing problems, resources planning problems, speech recognition,etc.

Optimality of A* search depends on the admissibility of heuristic function. To come up with an admissible heuristic is a challenging problem. In case we do not need an optimal solution and need a solution quickly then we can use inadmissible heuristic. But in order to get an optimal solution we need to come up with an admissible heuristic. Admissible heuristics are often found by relaxing the problems. For example, in the case of shortest path finding we can assume the distance between two nodes as straight line distance instead of going along the path in the graph.

To summarise, all the algorithms that we have seen till now differs only in the way the priority of the nodes in the fringe is defined. For DFS and BFS we used the time a node spent in the fringe. In Uniform Cost Search the cumulative cost is used as the priority to store the nodes in the fringe and in A* search the sum of backward cost(g(n)) and heuristic(h(n)) is used as priority to store the nodes in the fringe.DFS and BFS may or may not lead us to optimal solution. Uniform Cost Search will lead us to optimal solutions only if all the costs are positive. Greedy search may or may not lead to optimal solution. A* search will lead to optimal solution if heuristic function is admissible.


References


1. https://www.learneroo.com/modules/89/nodes/469
2. https://www.geeksforgeeks.org/search-algorithms-in-ai/
3. https://www.geeksforgeeks.org/search-algorithms-in-ai/
4. Lecture recordings and slides.