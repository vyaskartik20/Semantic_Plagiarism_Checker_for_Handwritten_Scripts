Artificial Intelligence Assignment (I have referred to the slide and explained in my own words.)


what is Artificial Intelligence ?

Artificial Intelligence is the study of making machines which can do almost everything which humans do.
we want to build a machine which will beat humans in the task at which humans are very good in today's world.
we want our future to be automated with the machines.we do not want any machine to rule over the world but there must be some
good features in these machines like the ability to think and take decisions based on the environment.
so, Artificial Intelligence is basically to apply our knowledge and making something intelligent.

what Artificial Intelligence can do?

Artificial Intelligence can do many interesting things. we can see many movies in which Artificial Intelligence is applied and can see how the world works very well.
In these movies, we see many things happening which we cannot imagine to happen in our real world.But with Artificial Intelligence, many things can happen which we cannot imagine.
self driving cars has been possible due to artificial Intelligence only.so, it can do many interesting things. 
speech converter is also an example of artificial Intelligence.It can also be used to classify things.for this to happen, we first need to train the machine
after which it can successfully classify things.


what is Rational decisions ?

Every machine will have some predefined goals. so,based on the environment and other factors, the machine will have to take decisions.Rational decisions are decisions
which makes it possible to maximally achieve the predefined goals.
Goals are also expressed in terms of utility of the outcome.Beings rational means maximizing the expected utility.

what is an agent?

An agent is something which can take some action after perceiving.Machine is also an agent because it can take action.
Agent can also be rational.

So, what is rational agent?

A rational agent can be defined as the one which take decisions so that the predefined goals is achieved maximally.
if we take the example of pacman, it's goal is to eat maximum dots in least amount of time.
so, if the pacman is able to achieve it's goal, we can say that pacman is rational agent.

There are two types of agent in artificial Intelligence, Reflex Agent and planning Agent.

so, what is reflex agent ?
reflex agent is the agent that takes decisions based on current state of the environment.
It may have memory to store current state of the environment.Before taking action, it does not consider what the consequences
may be.

Another agent is planning agent.
so, unlike the reflex agent, planning agent plans before taking action. it considers what the consequences may be due to the
action.it must have a model of the world will evolve with every action which is taken by the agent.
It formulates a goal and plans accordingly to reach the goal efficiently.

Planning can also be divided into two major categories:
Optimal and complete planning.

In optimal planning, the plan taken by the agent will be such that the agent reaches the goal with the least cost.

while in complete planning, the plan taken by the agent will be such that the agent will reach the goal for sure, but may not be with the least cost.



Now, let's see what is search problems ? 

To reach the goal, the agent has to find the path to reach the goal.
so, this is the problem of searching.

There are various terms related to search problems:  

State space : It consists of all possible states which the agent can go to
including the start state and end state.In state space, every information can be extracted
like what the start state was, all possible action, successor function and also the goal state where the agent will
finally stop searching.

Successor function : It means the agent will move from current state to next state with some cost.
The function which determines the next state based on the current state is called the successor function.

we can take the example of google map which we use very often.

when we want to go from our current state to some goal state, we follow some path to reach the goal.   
so, in this case the state space is set of all cities in the map.
And from the current state, we go to the adjacent state with some cost.
This is the successor function.
so, based on how the agent reaches the goal,the search problems can be divided into two cases:


uninformed search methods and informed search methods.

As the name suggests, in uninformed search, we try to explore all the paths from the current
position of the agent without knowing which path will lead to the goal with least cost.
Here, cost can be anything like time,distance, e.t.c depending on the problems.
we can say this technique of search to be blind search as it explores all the paths.

while in case of informed search, we do not just blindly follow all the path. At each step, we calculate some value which tells 
how far the agent is from the goal. This value is called as Heuristic value.
Agent tries to take the path with the least heuristic value which will be seen later.

Now coming to the uninformed search methods, there are three different methods which are
Depth-first search, breadth-first search and uniform cost search.

In depth first search, traversal start from one node and it will traverse the tree to the deepest level and when it cannot go further
deep, it backtracks and in this way, it will explore all the nodes in the tree until it reaches the goal state.
The data structure used here is stack. The time complexity of depth first search is O(b^m), where b is the branching factor and m is the number of level in the tree.

In breadth-first search, traversal start from one node and it will traverse the tree level wise and keep traversing until it reaches the goal state.
For breadth-first search,queue data structure is used for implementation.
The time complexity of breadth-first search is O(b^m) where b is the branching factor and m is the number of level in the tree.

In uniform cost search, traversal start from one node and to go from the current node to the next node requires some cost.It will push all the nodes in the fringe and pop out the node with the least cost.

Now, let's see what the state space graph is ?
It is basically a mathematical representation of a search problem.
The important thing here is that each state occurs only once in the state space graph.
In most cases, the  size of the state space graph is so huge that it is impossible to store the state space graph
in memory.
If we consider a general problem where one wants to go from one city to another.
Its a very common problem in our day to day lives.
so, we can represent our problem as a graph with nodes representing the various cities and the edges representing
the distance between two connected cities.

Now, let's see what is search Tree.
It is basically a tree in which from the current node,we see all the possible
states to where it can go to.In this search Tree, the start state is the root of the tree
and the children of each node is the successor.In the search Tree, we use priority queue to store the nodes.
each time, we poll the node with the highest priority from the priority queue and keep searching until it reaches the goal state.
while searching with the search tree, what we do is expand all the potential nodes.
we try to expand as few nodes as possible as it will improve the time complexity of the search.
so, let's see a general tree search ,how it works.
Either we will get a solution or failure when we cannot find the path.
keep pushing the nodes in the fringe until there are no more nodes to be expanded in which case it will return
false.at each state we choose a leaf node for expanding and pushing the nodes in the fringe.
we poll out the nodes from the fringe and if the current popped node is our goal state, then in this case we return true.


There is one difference between state space graph and search Tree. 
In state space graph,we find the path from the start state to the desired state
while in search Tree, each node is representing an entire path in the state space graph.


while we are searching in the state space graph, There are some properties of search Algorithm:

Complete: It simply means that if there exists a path from the start state to the desired state, then it will find the path
for sure , no matter how much time it takes to find the path. 

Optimal: It means that if the path exists from the start state to the desired state, it will not only find the path but also it will find the
path in the least time unlike complete. 

Let us see some properties of the depth first search.
It will expand the left part of the tree mostly because it first searches deep level of the tree but in the worst case, it may explore
the whole tree. It is complete only if we are able to prevent cycles in the graph because once
it finds cycles in the graph, it gets stuck there and won't be able to find the path. 
It is also not optimal because it always find the leftmost path.
It uses a LIFO(Last in first out) data structure which is stack. 

Now, let's see some properties of the breadth-first search. In breadth-first search, we expand
shallowest nodes first. This method will expand all the nodes above the shallowest
solution. The time complexity of breadth-first search is O(b^m) where b is the branching factor and m is the number of level in the tree.

In this method, since we are expanding the nodes level wise, so it will
always find the solution if it exists and that too in the least time
unlike depth-first search. Therefore, it is complete.
It may or may not be optimal depending on the cost of the edges.

so, a question can be asked like when is dfs better than bfs and when is bfs better than dfs ?
bfs is better than dfs in case where our goal is at earlier level in which case dfs may get stuck in the cycles in the depth of the tree where as in bfs since we expand the shallowest level first, it will definitely be better
than dfs in this case.

dfs may outperform bfs in the case where our goal is very deep in the tree in which case the dfs algorithm will
find the goal in less time since the dfs algorithm will first go to the depth of the tree and it will
find the goal whereas in bfs it will expand the shallowest level first.so it will take longer than dfs in this case.

Next concept is that of Iterative deepening.
The basic idea here is to take the dfs space advantage with that of bfs time advantage.
so, what we do in this is that we first run a dfs with depth of limit 1. if solution exists return the path else 
again run a dfs with depth limit of 2 and so on until it reaches the goal state.

Let's see what cost sensitive search is.
since bfs finds shortest path in terms of number os steps. it does not find the
least cost path. 
The basic idea is to expand the cheapest node first. The
fringe taken here is the priority queue for cumulative cost. It is kind of
djikstra algorithm. In dijkstra algorithm also,we do same thing like
expand all the nodes from the current node and relax all the nodes which have less cumulative cost
than what it is actually is and keep the adding nodes in the fringe until it reaches the goal state.

Let's see some properties of uniform cost search:
It basically will process all the nodes with the cost less than the cheapest solution.

If we assume that he best solution has a finite cost, then in that case it is complete.
It is also optimal.

One issue found with Uniform Cost Search is that it is a blind search and it does not provide
any information regarding the goal state.

Now one basic point if we notice is that all fringes are basically priority queue.


Now, after looking uninformed search, let's see what the informed search technique is and how it is better than uninformed search
technique.
There are many types of informed search technique like heuristic, Greedy Search, A* search.

let's see what the search heuristic is ?
In simple words, heuristic is any function that estimates how close a state is to a goal.
It is designed for some particular search problem. Some example of heuristic may be Manhattan distance
or euclidean distance.

If we consider the general problem of going from a state to a goal, wwe can apply the heuristic
to reach the goal.we assign the heuristic value to each state which basically
tells how close the state is to the goal.This heuristic value should be less than minimum of true
actual cost of going from current state to the goal state.

Let's consider another famous pancake problem.
so, this is basically we can imagine some plates of different dimensions kept
on each other.we would like to arrange them in a way such that the biggest pancake is at the bottom
and the dimensions of pancake keeps decreasing as we move from the top to the bottom.

This can be modeled as a search problem.we define the heuristic value as the number of the largest pancake that is still
out of order. we can define heuristic values to be something else as well
but let's keep it as defined.
 
so here also we start exploring all possible states and put them into our fringe
and poll out the state with the least heuristic until we reach the goal state.

Another type of Heuristic search technique is Greedy search. As the name suggests it will
always take the best possible from the current state. It does not consider
whether it will lead to optimal solution or not.
If we are trying to find the path using Greedy search, then the heuristic function will
be estimate of distance to the nearest goal for each state since the method being
used is Greedy search. It might often happen that it takes you straight to the wrong
goal.

We can combine the uniform cost search and Greedy search. 
Uniform cost search simply orders by the path cost and Greedy orders
by goal proximity(first the nodes which are closer to the goal).

so , this is A* search technique which simply orders by
the sum f(n) = g(n) + h(n), g(n) for backward cost and h(n) for Greedy search.

A* technique should only terminate when we are Dequeuing the goal state and not when
we are Enqueuing the node.
A* may not be optimal when actual bad cost is less than estimated good goal cost.
we need estimates of h value to be less than actual total cost to overcome this problem.

Now we saw that A* may not be optimal when actual bad cost is less than estimated good goal cost.
so, to overcome this problem, we define a term called admissible heuristic.In this case, admissible heuristic gives the
value which is less than total true cost.
A heuristic h is  admissible(optimistic) if:
0 <= h(n) <= h*(n) where h*(n) is the true cost to a nearest goal.

Now let's see uniform cost search vs A* search

uniform cost search as the name suggests it expands equally in all directions.

But A* expands mainly in towards the goal but tries its best to ensure the optimality.

This A* search finds the application in many fields like video games,Machine translation, e.t.c.

Now we would see how we calculate the heuristic in different cases.

Let's take a very famous problem of 8 puzzle in which we are given a 3*3 grid and there are numbers written on it from 1 to 8 and one blank is 
also there.we are given a start state and a goal state.we would like to convert the given start state
to the end state in the least number of operations. Foe this we use informed search technique.
The blank symbol can only go in four possible directions: up,down,left,right. 
so from the each state, we can go to maximum four possible states and we define the heuristic value for each state
as the number of misplaced cells. so out of all the possible states , we chose the one with the least heuristic value and expand this state.we keep doing this until we reach the end state in which the heuristic value
is equal to zero.

In short, if we summarize the A* search, 
it uses both backward and forward cost.
It is optimal with the admissible or consistent heuristic.
It expands the nodes in increasing order of f value which is equal to g(n) + h(n), or simply cost to node n plus it's heuristic.
